{
  "glm_4_7": {
    "model": "glm_4_7",
    "category": "inference_speed",
    "timestamp": 1768700936.8614614,
    "results": [
      {
        "test_method": "test_batch_inference_speed",
        "status": "passed",
        "output": "\nGLM-4.7-Flash-Flash Batch Size 1 Inference Speed:\n  Avg time per batch: 0.0053s\n  Tokens per second: 5649.55\n\nGLM-4.7-Flash-Flash Batch Size 2 Inference Speed:\n  Avg time per batch: 0.0055s\n  Tokens per second: 10947.95\n\nGLM-4.7-Flash-Flash Batch Size 4 Inference Speed:\n  Avg time per batch: 0.0053s\n  Tokens per second: 22777.80\n"
      },
      {
        "test_method": "test_generation_speed",
        "status": "passed",
        "output": "\nGLM-4.7-Flash-Flash Generation Speed:\n  Total time: 0.0207s\n  Generated text length: 46 chars\n  Characters per second: 2225.79\n"
      },
      {
        "test_method": "test_inference_speed_long_input",
        "status": "passed",
        "output": "\nGLM-4.7-Flash-Flash Long Input (100 tokens) Inference Speed:\n  Total time: 0.0168s\n  Avg time per inference: 0.0056s\n  Tokens per second: 17842.28\n"
      },
      {
        "test_method": "test_inference_speed_medium_input",
        "status": "passed",
        "output": "\nGLM-4.7-Flash-Flash Medium Input (50 tokens) Inference Speed:\n  Total time: 0.0272s\n  Avg time per inference: 0.0054s\n  Tokens per second: 9176.06\n"
      },
      {
        "test_method": "test_inference_speed_short_input",
        "status": "passed",
        "output": "\nGLM-4.7-Flash-Flash Short Input (20 tokens) Inference Speed:\n  Total time: 0.0267s\n  Avg time per inference: 0.0053s\n  Tokens per second: 3738.77\n"
      },
      {
        "test_method": "test_variable_length_inference_speed",
        "status": "passed",
        "output": "  Length 10: 1833.58 tokens/sec\n  Length 25: 4733.83 tokens/sec\n  Length 50: 9475.51 tokens/sec\n  Length 75: 13836.09 tokens/sec\n  Length 100: 18502.65 tokens/sec\n"
      }
    ],
    "status": "success"
  },
  "qwen3_4b_instruct_2507": {
    "model": "qwen3_4b_instruct_2507",
    "category": "inference_speed",
    "timestamp": 1768700937.3093145,
    "results": [
      {
        "test_method": "test_batch_inference_speed",
        "status": "passed",
        "output": "\nQwen3-4B-Instruct-2507 Batch Size 1 Inference Speed:\n  Avg time per batch: 0.0055s\n  Tokens per second: 5499.52\n\nQwen3-4B-Instruct-2507 Batch Size 2 Inference Speed:\n  Avg time per batch: 0.0055s\n  Tokens per second: 10859.32\n\nQwen3-4B-Instruct-2507 Batch Size 4 Inference Speed:\n  Avg time per batch: 0.0054s\n  Tokens per second: 22275.17\n"
      },
      {
        "test_method": "test_generation_speed",
        "status": "passed",
        "output": "\nQwen3-4B-Instruct-2507 Generation Speed:\n  Total time: 0.0203s\n  Generated text length: 46 chars\n  Characters per second: 2263.95\n"
      },
      {
        "test_method": "test_inference_speed_long_input",
        "status": "passed",
        "output": "\nQwen3-4B-Instruct-2507 Long Input (100 tokens) Inference Speed:\n  Total time: 0.0159s\n  Avg time per inference: 0.0053s\n  Tokens per second: 18827.68\n"
      },
      {
        "test_method": "test_inference_speed_medium_input",
        "status": "passed",
        "output": "\nQwen3-4B-Instruct-2507 Medium Input (50 tokens) Inference Speed:\n  Total time: 0.0273s\n  Avg time per inference: 0.0055s\n  Tokens per second: 9148.92\n"
      },
      {
        "test_method": "test_inference_speed_short_input",
        "status": "passed",
        "output": "\nQwen3-4B-Instruct-2507 Short Input (20 tokens) Inference Speed:\n  Total time: 0.0267s\n  Avg time per inference: 0.0053s\n  Tokens per second: 3746.89\n"
      },
      {
        "test_method": "test_variable_length_inference_speed",
        "status": "passed",
        "output": "  Length 10: 1801.70 tokens/sec\n  Length 25: 4754.51 tokens/sec\n  Length 50: 9316.40 tokens/sec\n  Length 75: 14359.03 tokens/sec\n  Length 100: 17958.91 tokens/sec\n"
      }
    ],
    "status": "success"
  },
  "qwen3_coder_30b": {
    "model": "qwen3_coder_30b",
    "category": "inference_speed",
    "timestamp": 1768700937.750945,
    "results": [
      {
        "test_method": "test_batch_inference_speed",
        "status": "passed",
        "output": "\nQwen3-Coder-30B Batch Size 1 Inference Speed:\n  Avg time per batch: 0.0054s\n  Tokens per second: 5578.37\n\nQwen3-Coder-30B Batch Size 2 Inference Speed:\n  Avg time per batch: 0.0055s\n  Tokens per second: 10970.09\n\nQwen3-Coder-30B Batch Size 4 Inference Speed:\n  Avg time per batch: 0.0056s\n  Tokens per second: 21406.25\n"
      },
      {
        "test_method": "test_generation_speed",
        "status": "passed",
        "output": "\nQwen3-Coder-30B Generation Speed:\n  Total time: 0.0205s\n  Generated text length: 46 chars\n  Characters per second: 2248.64\n"
      },
      {
        "test_method": "test_inference_speed_long_input",
        "status": "passed",
        "output": "\nQwen3-Coder-30B Long Input (100 tokens) Inference Speed:\n  Total time: 0.0164s\n  Avg time per inference: 0.0055s\n  Tokens per second: 18245.89\n"
      },
      {
        "test_method": "test_inference_speed_medium_input",
        "status": "passed",
        "output": "\nQwen3-Coder-30B Medium Input (50 tokens) Inference Speed:\n  Total time: 0.0272s\n  Avg time per inference: 0.0054s\n  Tokens per second: 9202.23\n"
      },
      {
        "test_method": "test_inference_speed_short_input",
        "status": "passed",
        "output": "\nQwen3-Coder-30B Short Input (20 tokens) Inference Speed:\n  Total time: 0.0277s\n  Avg time per inference: 0.0055s\n  Tokens per second: 3614.13\n"
      },
      {
        "test_method": "test_variable_length_inference_speed",
        "status": "passed",
        "output": "  Length 10: 1753.98 tokens/sec\n  Length 25: 4579.40 tokens/sec\n  Length 50: 9272.19 tokens/sec\n  Length 75: 13948.98 tokens/sec\n  Length 100: 18679.26 tokens/sec\n"
      }
    ],
    "status": "success"
  }
}
