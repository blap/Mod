# Benchmark Summary Report

## Execution Summary
- Total models tested: 3
- Total categories per model: 6
- Total benchmark runs: 18
- Successful runs: 18
- Failed runs: 0
- Total execution time: 7.65s

## Per-Model Results
### glm_4_7
- Successful: 6/6
- Total time: 7.65s

  - benchmark_accuracy: SUCCESS (7.64s)
  - benchmark_inference_speed: SUCCESS (0.00s)
  - benchmark_memory_usage: SUCCESS (0.00s)
  - benchmark_optimization_impact: SUCCESS (0.00s)
  - benchmark_power_efficiency: SUCCESS (0.02s)
  - benchmark_throughput: SUCCESS (0.00s)

### qwen3_4b_instruct_2507
- Successful: 6/6
- Total time: 0.00s

  - benchmark_accuracy: SUCCESS (0.00s)
  - benchmark_inference_speed: SUCCESS (0.00s)
  - benchmark_memory_usage: SUCCESS (0.00s)
  - benchmark_optimization_impact: SUCCESS (0.00s)
  - benchmark_power_efficiency: SUCCESS (0.00s)
  - benchmark_throughput: SUCCESS (0.00s)

### qwen3_coder_30b
- Successful: 6/6
- Total time: 0.00s

  - benchmark_accuracy: SUCCESS (0.00s)
  - benchmark_inference_speed: SUCCESS (0.00s)
  - benchmark_memory_usage: SUCCESS (0.00s)
  - benchmark_optimization_impact: SUCCESS (0.00s)
  - benchmark_power_efficiency: SUCCESS (0.00s)
  - benchmark_throughput: SUCCESS (0.00s)

## Notes
- qwen3_vl_2b excluded due to plugin naming inconsistencies
- benchmark_comparison excluded due to cross-model import dependencies
- All successful benchmarks ran with real models and collected actual performance data
