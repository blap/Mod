# Mock Optimization Impact Benchmark Report
Generated on: Sun Jan 18 08:28:53 2026
Total Duration: 0.00 seconds
## Aggregated Key Metrics
- **Avg Speed Improvement**: +47.67%
- **Avg Memory Improvement**: +29.01%
- **Accuracy Preserved Models**: 4/4

## Individual Model Results
### glm_4_7
- **Inference Speed**: 15.10 -> 16.17 tokens/sec (+7.14%)
- **Memory Usage**: 1671.51 -> 1353.16 MB avg (+19.05%)
- **Accuracy Preserved**: Yes (Score: 0.979)

### qwen3_4b_instruct_2507
- **Inference Speed**: 12.97 -> 23.30 tokens/sec (+79.68%)
- **Memory Usage**: 2034.71 -> 1438.15 MB avg (+29.32%)
- **Accuracy Preserved**: Yes (Score: 0.977)

### qwen3_coder_30b
- **Inference Speed**: 17.64 -> 15.54 tokens/sec (-11.91%)
- **Memory Usage**: 2004.12 -> 1381.54 MB avg (+31.07%)
- **Accuracy Preserved**: Yes (Score: 0.965)

### qwen3_vl_2b
- **Inference Speed**: 10.91 -> 23.55 tokens/sec (+115.80%)
- **Memory Usage**: 2184.94 -> 1385.30 MB avg (+36.60%)
- **Accuracy Preserved**: Yes (Score: 0.964)

## Key Findings
1. On average, optimizations improved inference speed by +47.67%.
2. Memory usage was reduced by +29.01% on average.
3. Model accuracy was preserved in 100.0% of cases.

## Executive Summary
The optimization techniques resulted in an average speed improvement of +47.67%.
Memory usage was reduced by an average of +29.01%.
Model accuracy was preserved in 100.0% of cases, indicating that optimizations maintain model quality.
