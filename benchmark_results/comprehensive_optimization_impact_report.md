# Mock Optimization Impact Benchmark Report
Generated on: Sun Jan 18 08:29:41 2026
Total Duration: 0.00 seconds
## Aggregated Key Metrics
- **Avg Speed Improvement**: +32.01%
- **Avg Memory Improvement**: +28.12%
- **Accuracy Preserved Models**: 4/4

## Individual Model Results
### glm_4_7
- **Inference Speed**: 13.65 -> 18.22 tokens/sec (+33.42%)
- **Memory Usage**: 1676.13 -> 1346.65 MB avg (+19.66%)
- **Accuracy Preserved**: Yes (Score: 0.971)

### qwen3_4b_instruct_2507
- **Inference Speed**: 13.12 -> 18.57 tokens/sec (+41.55%)
- **Memory Usage**: 2132.22 -> 1452.38 MB avg (+31.88%)
- **Accuracy Preserved**: Yes (Score: 0.983)

### qwen3_coder_30b
- **Inference Speed**: 17.48 -> 20.68 tokens/sec (+18.33%)
- **Memory Usage**: 2095.73 -> 1312.65 MB avg (+37.37%)
- **Accuracy Preserved**: Yes (Score: 0.978)

### qwen3_vl_2b
- **Inference Speed**: 17.90 -> 24.12 tokens/sec (+34.75%)
- **Memory Usage**: 2083.21 -> 1591.99 MB avg (+23.58%)
- **Accuracy Preserved**: Yes (Score: 0.967)

## Key Findings
1. On average, optimizations improved inference speed by +32.01%.
2. Memory usage was reduced by +28.12% on average.
3. Model accuracy was preserved in 100.0% of cases.

## Executive Summary
The optimization techniques resulted in an average speed improvement of +32.01%.
Memory usage was reduced by an average of +28.12%.
Model accuracy was preserved in 100.0% of cases, indicating that optimizations maintain model quality.
