name: Test

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: [3.8, 3.9, '3.10', '3.11']

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install system dependencies (Ubuntu)
      if: runner.os == 'Linux'
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential cmake libopenblas-dev

    - name: Install system dependencies (macOS)
      if: runner.os == 'macOS'
      run: |
        brew install cmake openblas

    - name: Install system dependencies (Windows)
      if: runner.os == 'Windows'
      run: |
        choco install cmake

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev,test]"
        pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu

    - name: Run unit tests with comprehensive reporting
      run: |
        python -m pytest tests/unit -v --generate-reports --reports-dir=./test_reports/unit --cov=src --cov-report=xml --cov-report=term-missing --cov-fail-under=80

    - name: Run integration tests with comprehensive reporting
      run: |
        python -m pytest tests/integration -v --generate-reports --reports-dir=./test_reports/integration

    - name: Run multimodal-specific tests with comprehensive reporting
      run: |
        python -m pytest tests/multimodal -v --generate-reports --reports-dir=./test_reports/multimodal

    - name: Run model-specific tests with comprehensive reporting
      run: |
        python -m pytest tests/models -v --generate-reports --reports-dir=./test_reports/models

    - name: Run performance tests (excluding slow markers) with comprehensive reporting
      run: |
        python -m pytest tests/performance -v -k "not slow" --generate-reports --reports-dir=./test_reports/performance

    - name: Validate model loading
      run: |
        python -c "
        import torch
        from src.qwen3_vl.models import Qwen3VLModel
        from src.qwen3_vl.config import Qwen3VLConfig

        # Test model initialization
        config = Qwen3VLConfig()
        model = Qwen3VLModel(config)
        print('Model initialized successfully')
        print(f'Model parameters: {sum(p.numel() for p in model.parameters()):,}')

        # Test forward pass with dummy inputs
        input_ids = torch.randint(0, 1000, (1, 128))
        pixel_values = torch.randn(1, 3, 224, 224)

        with torch.no_grad():
            output = model(input_ids=input_ids, pixel_values=pixel_values)
            print(f'Forward pass successful, output shape: {output.last_hidden_state.shape}')
        "

    - name: Upload coverage reports to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.os }}-${{ matrix.python-version }}
        path: |
          coverage.xml
          htmlcov/
        retention-days: 30