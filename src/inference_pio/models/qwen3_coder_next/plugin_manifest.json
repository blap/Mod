{
  "name": "Qwen3-Coder-Next",
  "version": "1.0.0",
  "author": "Alibaba Cloud",
  "description": "Qwen3-Coder-Next specialized language model with 80B parameters (3B activated), hybrid architecture (DeltaNet + Attention + MoE), and 262k context length.",
  "plugin_type": "MODEL_COMPONENT",
  "dependencies": [
    "torch",
    "transformers",
    "accelerate"
  ],
  "compatibility": {
    "torch_version": ">=2.2.0",
    "transformers_version": ">=4.38.0",
    "python_version": ">=3.9",
    "min_memory_gb": 160.0
  },
  "model_architecture": "Hybrid (Gated DeltaNet + Gated Attention + MoE)",
  "model_size": "80B",
  "required_memory_gb": 160.0,
  "supported_modalities": [
    "text"
  ],
  "license": "Proprietary",
  "tags": [
    "coding-assistant",
    "code-generation",
    "hybrid-architecture",
    "deltanet",
    "moe",
    "qwen",
    "80b",
    "long-context"
  ],
  "model_family": "Qwen",
  "num_parameters": 80000000000,
  "entry_point": {
    "module": ".plugin",
    "class": "Qwen3_Coder_Next_Plugin",
    "factory_function": "create_qwen3_coder_next_plugin"
  }
}
