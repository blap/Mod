"""\nIntel CPU optimized preprocessor for Qwen3-VL with dependency injection support.\n"""\nfrom typing import Dict, Any, Optional, List, Tuple\nfrom PIL import Image\nfrom transformers import PreTrainedTokenizerBase\nimport torch\nimport numpy as np\nfrom system.interfaces import Preprocessor, ConfigurableComponent\nfrom components.config.config import Qwen3VLConfig\n\n\nclass IntelCPUOptimizedPreprocessor(Preprocessor, ConfigurableComponent):\n    """\n    CPU-based preprocessor optimized specifically for Intel i5-10210U architecture\n    with dependency injection support.\n    """\n    \n    def __init__(self, config: Qwen3VLConfig):\n        """\n        Initialize the Intel-optimized preprocessor.\n        \n        Args:\n            config: Configuration for CPU optimizations\n        """\n        self.config = config\n        \n        # Validate config\n        if not isinstance(config, Qwen3VLConfig):\n            raise TypeError(f"config must be a Qwen3VLConfig instance, got {type(config)}")\n    \n    def get_config(self) -> Qwen3VLConfig:\n        """\n        Get the configuration object for this component.\n        \n        Returns:\n            Qwen3VLConfig object\n        """\n        return self.config\n    \n    def preprocess_batch(\n        self,\n        texts: List[str],\n        images: Optional[List[Image.Image]] = None,\n        return_tensors: str = "pt",\n        tokenizer: Optional[PreTrainedTokenizerBase] = None\n    ) -> Dict[str, Any]:\n        """\n        Preprocess a batch of texts and images with Intel i5-10210U-specific optimizations.\n        \n        Args:\n            texts: List of text strings to process\n            images: List of PIL Image objects to process (optional)\n            return_tensors: Format for returned tensors (default "pt" for PyTorch)\n            tokenizer: Tokenizer to use (optional)\n            \n        Returns:\n            Dictionary containing processed text and image tensors\n        """\n        # Use provided tokenizer or the one from initialization\n        tokenizer_to_use = tokenizer\n        \n        # Process texts with tokenizer\n        text_outputs = {}\n        if tokenizer_to_use and texts:\n            text_outputs = tokenizer_to_use(\n                texts,\n                padding="longest",\n                truncation=True,\n                max_length=self.config.max_position_embeddings,\n                return_tensors=return_tensors\n            )\n        \n        # Process images with cache-optimized operations\n        image_outputs = {}\n        if images:\n            image_outputs = self._process_images_optimized(images)\n        \n        # Combine outputs\n        result = {**text_outputs, **image_outputs}\n        \n        return result\n    \n    def _process_images_optimized(self, images: List[Image.Image]) -> Dict[str, torch.Tensor]:\n        """\n        Process images with cache-optimized operations for Intel i5-10210U.\n        \n        Args:\n            images: List of PIL Image objects to process\n            \n        Returns:\n            Dictionary containing processed image tensors\n        """\n        processed_images = []\n        \n        for img in images:\n            # Convert to RGB if necessary\n            if img.mode != 'RGB':\n                img = img.convert('RGB')\n            \n            # Resize image - optimized for cache efficiency\n            img = img.resize((self.config.vision_image_size, self.config.vision_image_size))\n            \n            # Convert to tensor and normalize using optimized operations\n            img_array = np.array(img).astype(np.float32)\n            \n            # Use contiguous memory layout for better cache access\n            img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).contiguous()  # HWC to CHW\n            \n            # Normalize to [0, 1] and then to ImageNet stats\n            img_tensor = img_tensor / 255.0\n            \n            # Apply normalization with cache-optimized operations\n            mean = torch.tensor([0.485, 0.456, 0.406], dtype=torch.float32).view(3, 1, 1)\n            std = torch.tensor([0.229, 0.224, 0.225], dtype=torch.float32).view(3, 1, 1)\n            img_tensor = (img_tensor - mean) / std\n            \n            processed_images.append(img_tensor)\n        \n        # Stack images into a batch with memory layout optimization\n        if processed_images:\n            # Use contiguous tensor for better memory access\n            pixel_values = torch.stack(processed_images, dim=0).contiguous()\n            return {"pixel_values": pixel_values}\n        else:\n            return {}