"""\nTiming Utilities for Performance Monitoring\n\nThis module provides utilities for measuring execution time of critical operations\nand collecting performance metrics. It includes decorators for timing functions,\ncontext managers for measuring code blocks, and utilities for collecting and\nreporting performance data.\n\nThe utilities are designed to be lightweight and efficient to minimize the\nperformance overhead of monitoring itself.\n"""\n\nimport time\nimport functools\nimport threading\nfrom typing import Dict, Any, Callable, Optional, Union\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass\nfrom collections import defaultdict\nimport logging\n\nfrom qwen3_vl.utils.debug_utils import conditional_debug
from qwen3_vl.utils.general_utils import is_debug_mode\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass TimingResult:\n    """\n    Data class to hold timing results.\n\n    Attributes:\n        execution_time (float): Time taken for execution in seconds\n        start_time (Optional[float]): Start time of the operation\n        end_time (Optional[float]): End time of the operation\n        operation_name (str): Name of the operation being timed\n        metadata (Optional[Dict[str, Any]]): Additional metadata about the operation\n    """\n    execution_time: float\n    start_time: Optional[float]\n    end_time: Optional[float]\n    operation_name: str\n    metadata: Optional[Dict[str, Any]] = None\n\n    def __post_init__(self):\n        if self.metadata is None:\n            self.metadata = {}\n\n\nclass Timer:\n    """\n    A timer class for measuring execution time of operations.\n    \n    This class provides both manual timing capabilities and integration\n    with context managers and decorators for automatic timing.\n    \n    Attributes:\n        start_time (Optional[float]): Time when the timer was started\n        end_time (Optional[float]): Time when the timer was stopped\n        elapsed_time (Optional[float]): Total elapsed time\n        operation_name (str): Name of the operation being timed\n    """\n    \n    def __init__(self, operation_name: str = "Operation"):\n        """\n        Initialize the timer.\n        \n        Args:\n            operation_name: Name of the operation to be timed\n        """\n        self.start_time: Optional[float] = None\n        self.end_time: Optional[float] = None\n        self.elapsed_time: Optional[float] = None\n        self.operation_name = operation_name\n        self._lock = threading.Lock()\n    \n    def start(self) -> None:\n        """Start the timer."""\n        with self._lock:\n            self.start_time = time.perf_counter()\n            self.end_time = None\n            self.elapsed_time = None\n    \n    def stop(self) -> float:\n        """\n        Stop the timer and return the elapsed time.\n        \n        Returns:\n            float: Elapsed time in seconds\n        """\n        with self._lock:\n            if self.start_time is None:\n                raise RuntimeError("Timer was not started")\n            \n            self.end_time = time.perf_counter()\n            self.elapsed_time = self.end_time - self.start_time\n            return self.elapsed_time\n    \n    def reset(self) -> None:\n        """Reset the timer to initial state."""\n        with self._lock:\n            self.start_time = None\n            self.end_time = None\n            self.elapsed_time = None\n    \n    def time_it(self, func: Callable, *args, **kwargs) -> tuple:\n        """\n        Time a function call and return both the result and timing information.\n        \n        Args:\n            func: Function to time\n            *args: Positional arguments to pass to the function\n            **kwargs: Keyword arguments to pass to the function\n            \n        Returns:\n            tuple: (result of function call, TimingResult object)\n        """\n        self.start()\n        try:\n            result = func(*args, **kwargs)\n            elapsed = self.stop()\n            timing_result = TimingResult(\n                execution_time=elapsed,\n                start_time=self.start_time,\n                end_time=self.end_time,\n                operation_name=self.operation_name\n            )\n            return result, timing_result\n        except Exception as e:\n            self.stop()  # Stop timer even if function raises an exception\n            raise e\n\n\ndef time_function(operation_name: Optional[str] = None, \n                 collect_metrics: bool = True) -> Callable:\n    """\n    Decorator to time function execution.\n    \n    Args:\n        operation_name: Name for the operation (defaults to function name)\n        collect_metrics: Whether to collect metrics using the centralized collector\n        \n    Returns:\n        Decorated function that measures execution time\n    """\n    def decorator(func: Callable) -> Callable:\n        nonlocal operation_name\n        if operation_name is None:\n            operation_name = func.__name__\n        \n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            timer = Timer(operation_name)\n            start_time = time.perf_counter()\n            \n            try:\n                result = func(*args, **kwargs)\n                end_time = time.perf_counter()\n                execution_time = end_time - start_time\n                \n                # Create timing result\n                timing_result = TimingResult(\n                    execution_time=execution_time,\n                    start_time=start_time,\n                    end_time=end_time,\n                    operation_name=operation_name\n                )\n                \n                # Log timing information\n                conditional_debug(logger, f"{operation_name} executed in {execution_time:.6f} seconds")\n                \n                # Optionally collect metrics\n                if collect_metrics:\n                    try:\n                        from centralized_metrics_collector import CentralizedMetricsCollector\n                        collector = CentralizedMetricsCollector.get_instance()\n                        collector.record_timing(operation_name, execution_time, func.__qualname__)\n                    except ImportError:\n                        # If centralized collector is not available, just log\n                        pass\n                    except Exception as e:\n                        logger.warning(f"Failed to record metrics: {e}")\n                \n                return result\n            except Exception as e:\n                end_time = time.perf_counter()\n                execution_time = end_time - start_time\n                logger.error(f"{operation_name} failed after {execution_time:.6f} seconds: {e}")\n                raise e\n        \n        return wrapper\n    return decorator\n\n\n@contextmanager\ndef time_block(operation_name: str, \n              collect_metrics: bool = True,\n              metadata: Optional[Dict[str, Any]] = None):\n    """\n    Context manager to time a block of code.\n    \n    Args:\n        operation_name: Name for the operation being timed\n        collect_metrics: Whether to collect metrics using the centralized collector\n        metadata: Additional metadata to associate with the timing result\n    """\n    if metadata is None:\n        metadata = {}\n    \n    timer = Timer(operation_name)\n    start_time = time.perf_counter()\n    \n    try:\n        yield timer\n        end_time = time.perf_counter()\n        execution_time = end_time - start_time\n        \n        timing_result = TimingResult(\n            execution_time=execution_time,\n            start_time=start_time,\n            end_time=end_time,\n            operation_name=operation_name,\n            metadata=metadata\n        )\n        \n        # Log timing information\n        conditional_debug(logger, f"{operation_name} executed in {execution_time:.6f} seconds")\n        \n        # Optionally collect metrics\n        if collect_metrics:\n            try:\n                from centralized_metrics_collector import CentralizedMetricsCollector\n                collector = CentralizedMetricsCollector.get_instance()\n                collector.record_timing(operation_name, execution_time, "time_block")\n            except ImportError:\n                # If centralized collector is not available, just log\n                pass\n            except Exception as e:\n                logger.warning(f"Failed to record metrics: {e}")\n    \n    except Exception as e:\n        end_time = time.perf_counter()\n        execution_time = end_time - start_time\n        logger.error(f"{operation_name} failed after {execution_time:.6f} seconds: {e}")\n        raise e\n\n\nclass PerformanceMonitor:\n    """\n    A performance monitor that tracks multiple operations over time.\n    \n    This class maintains statistics about multiple operations and provides\n    methods to retrieve performance metrics and trends.\n    \n    Attributes:\n        operations (Dict[str, list]): List of timing results for each operation\n        stats (Dict[str, Dict[str, float]]): Computed statistics for each operation\n        _lock (threading.Lock): Lock for thread-safe operations\n    """\n    \n    def __init__(self):\n        self.operations: Dict[str, list] = defaultdict(list)\n        self.stats: Dict[str, Dict[str, float]] = {}\n        self._lock = threading.Lock()\n    \n    def record_timing(self, operation_name: str, execution_time: float) -> None:\n        """\n        Record a timing result for an operation.\n        \n        Args:\n            operation_name: Name of the operation\n            execution_time: Execution time in seconds\n        """\n        with self._lock:\n            self.operations[operation_name].append(execution_time)\n            # Update statistics\n            self._update_stats(operation_name)\n    \n    def _update_stats(self, operation_name: str) -> None:\n        """\n        Update statistics for an operation.\n        \n        Args:\n            operation_name: Name of the operation to update stats for\n        """\n        times = self.operations[operation_name]\n        if not times:\n            return\n        \n        self.stats[operation_name] = {\n            'count': len(times),\n            'total_time': sum(times),\n            'avg_time': sum(times) / len(times),\n            'min_time': min(times),\n            'max_time': max(times),\n            'last_time': times[-1]\n        }\n    \n    def get_stats(self, operation_name: Optional[str] = None) -> Dict[str, Any]:\n        """\n        Get statistics for one or all operations.\n        \n        Args:\n            operation_name: Name of specific operation (None for all operations)\n            \n        Returns:\n            Dictionary containing statistics\n        """\n        with self._lock:\n            if operation_name:\n                return self.stats.get(operation_name, {})\n            else:\n                return dict(self.stats)\n    \n    def get_trend(self, operation_name: str, last_n: int = 10) -> Dict[str, Any]:\n        """\n        Get trend information for an operation based on recent measurements.\n        \n        Args:\n            operation_name: Name of the operation\n            last_n: Number of recent measurements to consider\n            \n        Returns:\n            Dictionary containing trend information\n        """\n        with self._lock:\n            times = self.operations[operation_name][-last_n:]\n            if not times:\n                return {}\n            \n            if len(times) < 2:\n                return {'trend': 'insufficient_data', 'avg_recent': times[0]}\n            \n            recent_avg = sum(times) / len(times)\n            earlier_avg = sum(times[:len(times)//2]) / max(1, len(times)//2)\n            \n            if recent_avg > earlier_avg * 1.1:  # 10% increase\n                trend = 'increasing'\n            elif recent_avg < earlier_avg * 0.9:  # 10% decrease\n                trend = 'decreasing'\n            else:\n                trend = 'stable'\n            \n            return {\n                'trend': trend,\n                'avg_recent': recent_avg,\n                'avg_earlier': earlier_avg,\n                'count': len(times)\n            }\n    \n    def reset(self) -> None:\n        """Reset all collected data."""\n        with self._lock:\n            self.operations.clear()\n            self.stats.clear()\n\n\n# Global performance monitor instance\n_global_monitor = PerformanceMonitor()\n\n\ndef get_global_monitor() -> PerformanceMonitor:\n    """\n    Get the global performance monitor instance.\n    \n    Returns:\n        Global PerformanceMonitor instance\n    """\n    return _global_monitor\n\n\ndef benchmark_function(func: Callable, \n                      *args, \n                      iterations: int = 10, \n                      **kwargs) -> Dict[str, float]:\n    """\n    Benchmark a function by running it multiple times.\n    \n    Args:\n        func: Function to benchmark\n        *args: Arguments to pass to the function\n        iterations: Number of iterations to run\n        **kwargs: Keyword arguments to pass to the function\n        \n    Returns:\n        Dictionary containing benchmark statistics\n    """\n    times = []\n    \n    # Warmup\n    for _ in range(3):\n        func(*args, **kwargs)\n    \n    # Actual benchmark\n    for _ in range(iterations):\n        start = time.perf_counter()\n        func(*args, **kwargs)\n        end = time.perf_counter()\n        times.append(end - start)\n    \n    return {\n        'count': len(times),\n        'total_time': sum(times),\n        'avg_time': sum(times) / len(times),\n        'min_time': min(times),\n        'max_time': max(times),\n        'std_dev': (sum((t - sum(times) / len(times)) ** 2 for t in times) / len(times)) ** 0.5 if times else 0\n    }\n\n\ndef measure_memory_usage(func: Callable, *args, **kwargs) -> tuple:\n    """\n    Measure both execution time and memory usage of a function.\n    \n    Args:\n        func: Function to measure\n        *args: Arguments to pass to the function\n        **kwargs: Keyword arguments to pass to the function\n        \n    Returns:\n        tuple: (function result, timing result, memory delta in bytes)\n    """\n    try:\n        import psutil\n        import os\n        \n        process = psutil.Process(os.getpid())\n        start_memory = process.memory_info().rss  # Resident Set Size\n        \n        start_time = time.perf_counter()\n        result = func(*args, **kwargs)\n        end_time = time.perf_counter()\n        \n        end_memory = process.memory_info().rss\n        memory_delta = end_memory - start_memory\n        \n        timing_result = TimingResult(\n            execution_time=end_time - start_time,\n            start_time=start_time,\n            end_time=end_time,\n            operation_name=func.__name__\n        )\n        \n        return result, timing_result, memory_delta\n    \n    except ImportError:\n        # If psutil is not available, just measure time\n        start_time = time.perf_counter()\n        result = func(*args, **kwargs)\n        end_time = time.perf_counter()\n        \n        timing_result = TimingResult(\n            execution_time=end_time - start_time,\n            start_time=start_time,\n            end_time=end_time,\n            operation_name=func.__name__\n        )\n        \n        return result, timing_result, 0  # Return 0 for memory delta if psutil not available\n\n\n# Convenience functions for common timing operations\ndef time_execution(operation_name: str, \n                  collect_metrics: bool = True,\n                  metadata: Optional[Dict[str, Any]] = None) -> Callable:\n    """\n    Decorator to time function execution with additional metadata.\n    \n    Args:\n        operation_name: Name for the operation being timed\n        collect_metrics: Whether to collect metrics using the centralized collector\n        metadata: Additional metadata to associate with the timing result\n        \n    Returns:\n        Decorator function\n    """\n    def decorator(func: Callable) -> Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            with time_block(operation_name, collect_metrics, metadata):\n                return func(*args, **kwargs)\n        return wrapper\n    return decorator\n\n\ndef measure_throughput(operation_name: str, \n                      batch_size: int, \n                      collect_metrics: bool = True) -> Callable:\n    """\n    Decorator to measure throughput (operations per second) of a function.\n    \n    Args:\n        operation_name: Name for the operation being measured\n        batch_size: Number of items processed in each call\n        collect_metrics: Whether to collect metrics using the centralized collector\n        \n    Returns:\n        Decorator function\n    """\n    def decorator(func: Callable) -> Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            start_time = time.perf_counter()\n            result = func(*args, **kwargs)\n            end_time = time.perf_counter()\n            \n            execution_time = end_time - start_time\n            throughput = batch_size / execution_time if execution_time > 0 else 0\n            \n            conditional_debug(logger, f"{operation_name} throughput: {throughput:.2f} items/sec")\n            \n            if collect_metrics:\n                try:\n                    from centralized_metrics_collector import CentralizedMetricsCollector\n                    collector = CentralizedMetricsCollector.get_instance()\n                    collector.record_metric(operation_name + "_throughput", throughput, "throughput")\n                except ImportError:\n                    pass\n                except Exception as e:\n                    logger.warning(f"Failed to record throughput metrics: {e}")\n            \n            return result\n        return wrapper\n    return decorator\n\n\ndef track_resource_usage(operation_name: str, \n                        collect_metrics: bool = True) -> Callable:\n    """\n    Decorator to track resource usage including CPU, memory, and execution time.\n    \n    Args:\n        operation_name: Name for the operation being tracked\n        collect_metrics: Whether to collect metrics using the centralized collector\n        \n    Returns:\n        Decorator function\n    """\n    def decorator(func: Callable) -> Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                import psutil\n                import os\n                process = psutil.Process(os.getpid())\n                \n                # Capture initial resource usage\n                start_cpu_percent = process.cpu_percent()\n                start_memory = process.memory_info().rss\n                start_time = time.perf_counter()\n                \n                result = func(*args, **kwargs)\n                \n                # Capture final resource usage\n                end_time = time.perf_counter()\n                end_memory = process.memory_info().rss\n                end_cpu_percent = process.cpu_percent()\n                \n                execution_time = end_time - start_time\n                memory_delta = end_memory - start_memory\n                \n                conditional_debug(logger, f"{operation_name} - Time: {execution_time:.6f}s, "\n                           f"Memory delta: {memory_delta} bytes")\n                \n                if collect_metrics:\n                    try:\n                        from centralized_metrics_collector import CentralizedMetricsCollector\n                        collector = CentralizedMetricsCollector.get_instance()\n                        collector.record_metric(operation_name + "_time", execution_time, "time")\n                        collector.record_metric(operation_name + "_memory_delta", memory_delta, "memory")\n                    except ImportError:\n                        pass\n                    except Exception as e:\n                        logger.warning(f"Failed to record resource metrics: {e}")\n                \n                return result\n            except ImportError:\n                # If psutil is not available, just measure time\n                start_time = time.perf_counter()\n                result = func(*args, **kwargs)\n                end_time = time.perf_counter()\n                \n                execution_time = end_time - start_time\n                conditional_debug(logger, f"{operation_name} - Time: {execution_time:.6f}s (resource tracking unavailable)")\n                \n                if collect_metrics:\n                    try:\n                        from centralized_metrics_collector import CentralizedMetricsCollector\n                        collector = CentralizedMetricsCollector.get_instance()\n                        collector.record_metric(operation_name + "_time", execution_time, "time")\n                    except ImportError:\n                        pass\n                    except Exception as e:\n                        logger.warning(f"Failed to record time metrics: {e}")\n                \n                return result\n        return wrapper\n    return decorator\n\n\n# Initialize logging if not already configured\nif not logging.getLogger().handlers:\n    logging.basicConfig(level=logging.INFO)