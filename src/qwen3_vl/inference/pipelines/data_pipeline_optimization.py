"""\nData Pipeline Optimization for Qwen3-VL-2B-Instruct\nOptimized for Intel i5-10210U + NVIDIA SM61 Hardware Configuration\n"""\n\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom torch.utils.data import DataLoader, Dataset\nfrom typing import Optional, Dict, Any, List, Tuple, Union, Callable\nfrom dataclasses import dataclass\nimport time\nimport threading\nimport queue\nimport logging\nfrom collections import defaultdict, deque\nimport psutil\nimport os\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\nfrom inference.components.memory.pre_allocated_tensor_caches import get_cached_tensor, return_cached_tensor, get_tensor_cache_statistics\nfrom inference.components.memory.cpu_gpu_memory_transfer_optimization import HardwareAwareTransferOptimizer, transfer_tensor_with_optimization\n\n\n@dataclass\nclass DataPipelineConfig:\n    """Configuration for the optimized data pipeline."""\n    # Data loading configuration\n    batch_size: int = 8\n    num_workers: int = 2  # For Intel i5-10210U (4 cores), use fewer workers to avoid memory issues\n    pin_memory: bool = True  # Enable pinned memory for faster GPU transfers\n    persistent_workers: bool = True  # Keep workers alive between epochs\n    \n    # Preprocessing configuration\n    image_resize_size: Tuple[int, int] = (224, 224)\n    max_text_length: int = 512\n    use_fast_tokenizer: bool = True\n    \n    # GPU transfer configuration\n    async_transfer: bool = True  # Use asynchronous transfers\n    transfer_batch_size: int = 1  # Transfer batches to GPU in chunks\n    \n    # Caching configuration\n    enable_tensor_caching: bool = True\n    enable_data_caching: bool = True\n    cache_size: int = 100  # Number of items to cache\n    \n    # Performance optimization\n    prefetch_factor: int = 2  # Prefetch 2 batches ahead\n    memory_threshold: float = 0.8  # Percentage of memory to use before throttling\n    clear_cache_interval: int = 10  # Clear cache every N batches\n\n\nclass OptimizedDataset(Dataset):\n    """\n    Optimized dataset wrapper that handles preprocessing and caching.\n    """\n    def __init__(self, \n                 dataset: Dataset, \n                 tokenizer: Optional[Callable] = None, \n                 config: DataPipelineConfig = None):\n        self.dataset = dataset\n        self.tokenizer = tokenizer\n        self.config = config or DataPipelineConfig()\n        \n        # Preprocessing transforms\n        self.transform = transforms.Compose([\n            transforms.Resize(self.config.image_resize_size),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                               std=[0.229, 0.224, 0.225])\n        ])\n        \n        # Caching for preprocessed data\n        self.data_cache = {}\n        self.cache_hits = 0\n        self.cache_misses = 0\n        \n        # Performance tracking\n        self.access_times = []\n        \n    def __len__(self):\n        return len(self.dataset)\n    \n    def __getitem__(self, idx: int) -> Dict[str, Any]:\n        start_time = time.time()\n        \n        # Check cache first\n        if self.config.enable_data_caching and idx in self.data_cache:\n            self.cache_hits += 1\n            item = self.data_cache[idx]\n        else:\n            self.cache_misses += 1\n            # Get raw data from underlying dataset\n            raw_item = self.dataset[idx]\n            item = self._preprocess_item(raw_item)\n            \n            # Cache if enabled\n            if self.config.enable_data_caching:\n                self.data_cache[idx] = item\n                # Trim cache if too large\n                if len(self.data_cache) > self.config.cache_size:\n                    # Remove oldest entries (FIFO)\n                    oldest_key = next(iter(self.data_cache))\n                    del self.data_cache[oldest_key]\n        \n        self.access_times.append(time.time() - start_time)\n        return item\n    \n    def _preprocess_item(self, raw_item: Any) -> Dict[str, Any]:\n        """\n        Preprocess a single item from the dataset.\n        """\n        if isinstance(raw_item, dict):\n            # Assume it's already in the right format\n            processed_item = raw_item.copy()\n        elif isinstance(raw_item, tuple) and len(raw_item) >= 2:\n            # Assume (text, image) format\n            text, image = raw_item[:2]\n            processed_item = {\n                'text': text,\n                'image': self._process_image(image) if isinstance(image, Image.Image) else image\n            }\n            if len(raw_item) > 2:\n                processed_item['label'] = raw_item[2]\n        else:\n            # Single element - assume it's text\n            processed_item = {'text': raw_item}\n        \n        # Process text if tokenizer is provided\n        if self.tokenizer and 'text' in processed_item:\n            tokenized = self.tokenizer(\n                processed_item['text'],\n                padding='max_length',\n                truncation=True,\n                max_length=self.config.max_text_length,\n                return_tensors='pt'\n            )\n            processed_item.update(tokenized)\n        \n        return processed_item\n    \n    def _process_image(self, image: Image.Image) -> torch.Tensor:\n        """\n        Process a PIL image into a tensor.\n        """\n        if image.mode != 'RGB':\n            image = image.convert('RGB')\n        return self.transform(image)\n\n    def _collate_fn(self, batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n        """\n        Custom collate function to handle the batched data properly.\n        """\n        if not batch:\n            return {}\n\n        # Get the keys from the first item\n        keys = batch[0].keys()\n        result = {}\n\n        for key in keys:\n            values = [item[key] for item in batch]\n\n            # If values are tensors, stack them\n            if all(isinstance(v, torch.Tensor) for v in values):\n                result[key] = torch.stack(values, dim=0)\n            # If values are not tensors, keep as list\n            else:\n                result[key] = values\n\n        return result\n    \n    def get_cache_stats(self) -> Dict[str, int]:\n        """Get cache statistics."""\n        total_accesses = self.cache_hits + self.cache_misses\n        hit_rate = self.cache_hits / total_accesses if total_accesses > 0 else 0\n        return {\n            'cache_hits': self.cache_hits,\n            'cache_misses': self.cache_misses,\n            'hit_rate': hit_rate,\n            'cache_size': len(self.data_cache)\n        }\n    \n    def get_performance_stats(self) -> Dict[str, float]:\n        """Get performance statistics."""\n        if self.access_times:\n            avg_time = sum(self.access_times) / len(self.access_times)\n            return {\n                'avg_access_time': avg_time,\n                'total_accesses': len(self.access_times)\n            }\n        return {\n            'avg_access_time': 0.0,\n            'total_accesses': 0\n        }\n\n\nclass AsyncDataTransferBuffer:\n    """\n    Asynchronous buffer for transferring data to GPU with overlapping computation.\n    """\n    def __init__(self, \n                 max_buffer_size: int = 10, \n                 device: torch.device = None):\n        self.max_buffer_size = max_buffer_size\n        self.device = device or torch.device("cuda" if torch.cuda.is_available() else "cpu")\n        \n        # Queue for pending transfers\n        self.transfer_queue = queue.Queue(maxsize=max_buffer_size)\n        \n        # Queue for completed transfers\n        self.completed_queue = queue.Queue(maxsize=max_buffer_size)\n        \n        # Thread for handling transfers\n        self.transfer_thread = threading.Thread(target=self._transfer_worker, daemon=True)\n        self.transfer_thread.start()\n        \n        # CUDA streams for overlapping transfers\n        self.transfer_stream = torch.cuda.Stream() if torch.cuda.is_available() else None\n        self.main_stream = torch.cuda.current_stream() if torch.cuda.is_available() else None\n        \n        # Statistics\n        self.stats = {\n            'transfers_initiated': 0,\n            'transfers_completed': 0,\n            'transfer_time': 0.0\n        }\n    \n    def _transfer_worker(self):\n        """\n        Worker thread that handles asynchronous transfers.\n        """\n        while True:\n            try:\n                # Get item from transfer queue\n                item = self.transfer_queue.get(timeout=1.0)\n                if item is None:  # Sentinel to stop thread\n                    break\n                \n                start_time = time.time()\n                \n                # Transfer to device\n                if isinstance(item, dict):\n                    transferred_item = {}\n                    for key, value in item.items():\n                        if isinstance(value, torch.Tensor):\n                            transferred_item[key] = transfer_tensor_with_optimization(value, self.device)\n                        else:\n                            transferred_item[key] = value\n                elif isinstance(item, torch.Tensor):\n                    transferred_item = transfer_tensor_with_optimization(item, self.device)\n                else:\n                    transferred_item = item\n                \n                # Update statistics\n                self.stats['transfers_completed'] += 1\n                self.stats['transfer_time'] += time.time() - start_time\n                \n                # Put completed item in completed queue\n                self.completed_queue.put(transferred_item)\n                \n                self.transfer_queue.task_done()\n            except queue.Empty:\n                continue\n    \n    def enqueue_transfer(self, item: Any):\n        """\n        Enqueue an item for transfer to GPU.\n        """\n        self.transfer_queue.put(item)\n        self.stats['transfers_initiated'] += 1\n    \n    def get_transferred_item(self, timeout: float = 1.0) -> Any:\n        """\n        Get a transferred item from the completed queue.\n        """\n        try:\n            return self.completed_queue.get(timeout=timeout)\n        except queue.Empty:\n            return None\n    \n    def get_stats(self) -> Dict[str, Any]:\n        """Get transfer statistics."""\n        return self.stats.copy()\n    \n    def stop(self):\n        """Stop the transfer worker."""\n        self.transfer_queue.put(None)  # Sentinel to stop thread\n\n\nclass OptimizedDataLoader:\n    """\n    Optimized DataLoader with advanced features for efficient data pipeline.\n    """\n    def __init__(self, \n                 dataset: Dataset, \n                 config: DataPipelineConfig = None,\n                 tokenizer: Optional[Callable] = None,\n                 **kwargs):\n        self.config = config or DataPipelineConfig()\n        \n        # Wrap the dataset with optimizations\n        self.optimized_dataset = OptimizedDataset(dataset, tokenizer, self.config)\n        \n        # Create async transfer buffer\n        self.transfer_buffer = AsyncDataTransferBuffer(device=torch.device("cuda" if torch.cuda.is_available() else "cpu"))\n        \n        # Update kwargs with optimized parameters\n        loader_kwargs = {\n            'batch_size': self.config.batch_size,\n            'num_workers': self.config.num_workers,\n            'pin_memory': self.config.pin_memory,\n            'collate_fn': self.optimized_dataset._collate_fn  # Use custom collate function\n        }\n\n        # Only add prefetch_factor and persistent_workers if num_workers > 0 (required by PyTorch)\n        if self.config.num_workers > 0:\n            loader_kwargs['prefetch_factor'] = self.config.prefetch_factor\n            loader_kwargs['persistent_workers'] = self.config.persistent_workers\n        else:\n            # If num_workers is 0, we can't use persistent_workers\n            pass  # persistent_workers is not used when num_workers is 0\n\n        # Override with any user-provided kwargs\n        loader_kwargs.update(kwargs)\n\n        # Create the underlying DataLoader\n        self.dataloader = DataLoader(self.optimized_dataset, **loader_kwargs)\n        \n        # Performance tracking\n        self.batch_times = []\n        self.transfer_times = []\n        \n        # Memory monitoring\n        self.memory_threshold = self.config.memory_threshold\n        self.last_memory_check = time.time()\n    \n    def __iter__(self):\n        """Iterate through the dataset with optimized preprocessing and transfer."""\n        for batch in self.dataloader:\n            start_time = time.time()\n            \n            # Check memory usage and potentially clear cache\n            if time.time() - self.last_memory_check > 5:  # Check every 5 seconds\n                self._check_memory_usage()\n                self.last_memory_check = time.time()\n            \n            # Transfer to GPU if available\n            if torch.cuda.is_available():\n                if self.config.async_transfer:\n                    # Use async transfer buffer\n                    self.transfer_buffer.enqueue_transfer(batch)\n                    transferred_batch = self.transfer_buffer.get_transferred_item(timeout=2.0)\n                    \n                    # If async transfer didn't complete in time, do sync transfer\n                    if transferred_batch is None:\n                        transferred_batch = self._transfer_batch_sync(batch)\n                else:\n                    # Synchronous transfer\n                    transferred_batch = self._transfer_batch_sync(batch)\n            else:\n                # CPU-only\n                transferred_batch = batch\n            \n            batch_time = time.time() - start_time\n            self.batch_times.append(batch_time)\n            \n            yield transferred_batch\n    \n    def _transfer_batch_sync(self, batch: Any) -> Any:\n        """Synchronously transfer a batch to GPU."""\n        start_time = time.time()\n        \n        if isinstance(batch, dict):\n            transferred_batch = {}\n            for key, value in batch.items():\n                if isinstance(value, torch.Tensor):\n                    transferred_batch[key] = transfer_tensor_with_optimization(value, torch.device("cuda"))\n                else:\n                    transferred_batch[key] = value\n        elif isinstance(batch, torch.Tensor):\n            transferred_batch = transfer_tensor_with_optimization(batch, torch.device("cuda"))\n        elif isinstance(batch, (list, tuple)):\n            transferred_batch = []\n            for item in batch:\n                if isinstance(item, torch.Tensor):\n                    transferred_batch.append(transfer_tensor_with_optimization(item, torch.device("cuda")))\n                else:\n                    transferred_batch.append(item)\n        else:\n            transferred_batch = batch\n        \n        self.transfer_times.append(time.time() - start_time)\n        return transferred_batch\n    \n    def _check_memory_usage(self):\n        """Check memory usage and clear cache if necessary."""\n        if torch.cuda.is_available():\n            gpu_memory_allocated = torch.cuda.memory_allocated()\n            gpu_memory_reserved = torch.cuda.memory_reserved()\n            gpu_memory_total = torch.cuda.get_device_properties(0).total_memory\n            \n            memory_usage = gpu_memory_reserved / gpu_memory_total\n            if memory_usage > self.memory_threshold:\n                # Clear PyTorch cache\n                torch.cuda.empty_cache()\n        else:\n            # Check system memory on CPU\n            memory_percent = psutil.virtual_memory().percent / 100.0\n            if memory_percent > self.memory_threshold:\n                # Clear cache\n                import gc\n                gc.collect()\n    \n    def __len__(self):\n        return len(self.dataloader)\n    \n    def get_dataset_stats(self) -> Dict[str, Any]:\n        """Get statistics from the underlying optimized dataset."""\n        return {\n            'dataset_cache_stats': self.optimized_dataset.get_cache_stats(),\n            'dataset_performance_stats': self.optimized_dataset.get_performance_stats()\n        }\n    \n    def get_pipeline_stats(self) -> Dict[str, Any]:\n        """Get comprehensive pipeline statistics."""\n        avg_batch_time = sum(self.batch_times) / len(self.batch_times) if self.batch_times else 0\n        avg_transfer_time = sum(self.transfer_times) / len(self.transfer_times) if self.transfer_times else 0\n        \n        return {\n            'avg_batch_time': avg_batch_time,\n            'avg_transfer_time': avg_transfer_time,\n            'total_batches_processed': len(self.batch_times),\n            'transfer_buffer_stats': self.transfer_buffer.get_stats(),\n            'tensor_cache_stats': get_tensor_cache_statistics(),\n            'dataset_stats': self.get_dataset_stats()\n        }\n    \n    def clear_caches(self):\n        """Clear all caches to free memory."""\n        # Clear tensor cache\nfrom inference.components.memory.pre_allocated_tensor_caches import clear_tensor_cache\n        clear_tensor_cache()\n        \n        # Clear dataset cache\n        self.optimized_dataset.data_cache.clear()\n        \n        # Clear PyTorch cache\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        \n        import gc\n        gc.collect()\n\n\nclass DataPipelineOptimizer:\n    """\n    Main class for optimizing the entire data pipeline.\n    """\n    def __init__(self, config: DataPipelineConfig = None):\n        self.config = config or DataPipelineConfig()\n        self.transfer_optimizer = HardwareAwareTransferOptimizer()\n        \n        # Performance tracking\n        self.pipeline_stats = {\n            'total_data_loading_time': 0.0,\n            'total_preprocessing_time': 0.0,\n            'total_transfer_time': 0.0,\n            'total_pipeline_time': 0.0\n        }\n    \n    def create_optimized_dataloader(self, \n                                  dataset: Dataset, \n                                  tokenizer: Optional[Callable] = None,\n                                  **kwargs) -> OptimizedDataLoader:\n        """\n        Create an optimized DataLoader with the specified configuration.\n        """\n        return OptimizedDataLoader(\n            dataset=dataset,\n            config=self.config,\n            tokenizer=tokenizer,\n            **kwargs\n        )\n    \n    def preprocess_batch(self, batch: Dict[str, Any]) -> Dict[str, Any]:\n        """\n        Apply additional preprocessing optimizations to a batch.\n        """\n        start_time = time.time()\n        \n        # Apply any additional preprocessing optimizations here\n        # For now, we'll just return the batch as-is since preprocessing\n        # is already handled in the OptimizedDataset\n        \n        self.pipeline_stats['total_preprocessing_time'] += time.time() - start_time\n        return batch\n    \n    def transfer_batch_to_device(self, \n                                batch: Dict[str, Any], \n                                device: torch.device) -> Dict[str, Any]:\n        """\n        Transfer a batch to the specified device with optimizations.\n        """\n        start_time = time.time()\n        \n        transferred_batch = {}\n        for key, value in batch.items():\n            if isinstance(value, torch.Tensor):\n                transferred_batch[key] = self.transfer_optimizer.optimize_transfer_for_hardware(value, device)\n            else:\n                transferred_batch[key] = value\n        \n        self.pipeline_stats['total_transfer_time'] += time.time() - start_time\n        return transferred_batch\n    \n    def get_pipeline_performance(self) -> Dict[str, float]:\n        """Get overall pipeline performance metrics."""\n        return self.pipeline_stats.copy()\n\n\n# Utility functions for common pipeline operations\ndef create_multimodal_pipeline(dataset: Dataset, \n                              tokenizer: Optional[Callable] = None,\n                              config: DataPipelineConfig = None) -> OptimizedDataLoader:\n    """\n    Create an optimized pipeline specifically for multimodal data (text + images).\n    """\n    optimizer = DataPipelineOptimizer(config)\n    return optimizer.create_optimized_dataloader(dataset, tokenizer)\n\n\ndef benchmark_pipeline_performance(dataloader: OptimizedDataLoader, \n                                 num_batches: int = 10) -> Dict[str, Any]:\n    """\n    Benchmark the performance of the optimized pipeline.\n    """\n    print(f"Benchmarking pipeline performance for {num_batches} batches...")\n    \n    start_time = time.time()\n    \n    # Process batches and measure performance\n    batch_count = 0\n    for batch in dataloader:\n        batch_count += 1\n        if batch_count >= num_batches:\n            break\n    \n    total_time = time.time() - start_time\n    \n    # Get pipeline statistics\n    stats = dataloader.get_pipeline_stats()\n    \n    benchmark_results = {\n        'total_time': total_time,\n        'batches_processed': batch_count,\n        'avg_time_per_batch': total_time / batch_count if batch_count > 0 else 0,\n        'throughput_batches_per_sec': batch_count / total_time if total_time > 0 else 0,\n        'pipeline_stats': stats\n    }\n    \n    print(f"Pipeline benchmark completed:")\n    print(f"  Total time: {total_time:.4f}s")\n    print(f"  Batches processed: {batch_count}")\n    print(f"  Avg time per batch: {benchmark_results['avg_time_per_batch']:.4f}s")\n    print(f"  Throughput: {benchmark_results['throughput_batches_per_sec']:.2f} batches/sec")\n    \n    return benchmark_results\n\n\n# Example usage and testing\ndef test_optimized_pipeline():\n    """\n    Test the optimized data pipeline with a dummy dataset.\n    """\n    print("Testing Optimized Data Pipeline...")\n    \n    # Create a dummy dataset\n    class DummyDataset(Dataset):\n        def __init__(self, size=100):\n            self.size = size\n            self.texts = [f"Sample text {i}" for i in range(size)]\n            # Create dummy images\n            self.images = [Image.new('RGB', (224, 224), color='red') for _ in range(size)]\n        \n        def __len__(self):\n            return self.size\n        \n        def __getitem__(self, idx):\n            return {\n                'text': self.texts[idx],\n                'image': self.images[idx]\n            }\n    \n    # Create dummy tokenizer\n    def dummy_tokenizer(text, **kwargs):\n        # Simulate tokenization\n        return {\n            'input_ids': torch.randint(0, 1000, (1, 128)),\n            'attention_mask': torch.ones(1, 128)\n        }\n    \n    # Create dataset\n    dataset = DummyDataset(size=50)\n    \n    # Create optimized pipeline\n    config = DataPipelineConfig(\n        batch_size=4,\n        num_workers=2,\n        pin_memory=True,\n        async_transfer=True,\n        enable_data_caching=True,\n        cache_size=20\n    )\n    \n    optimizer = DataPipelineOptimizer(config)\n    dataloader = optimizer.create_optimized_dataloader(dataset, dummy_tokenizer)\n    \n    print("Processing batches with optimized pipeline...")\n    \n    # Process a few batches\n    batch_count = 0\n    for batch in dataloader:\n        batch_count += 1\n        print(f"  Processed batch {batch_count}, batch size: {len(batch.get('input_ids', []))}")\n        if batch_count >= 5:  # Process 5 batches for testing\n            break\n    \n    # Get and display statistics\n    stats = dataloader.get_pipeline_stats()\n    print("\nPipeline Statistics:")\n    print(f"  Average batch time: {stats['avg_batch_time']:.4f}s")\n    print(f"  Average transfer time: {stats['avg_transfer_time']:.4f}s")\n    print(f"  Dataset cache hit rate: {stats['dataset_stats']['dataset_cache_stats']['hit_rate']:.4f}")\n    print(f"  Total batches processed: {stats['total_batches_processed']}")\n    \n    # Benchmark performance\n    benchmark_results = benchmark_pipeline_performance(dataloader, num_batches=10)\n    \n    # Test cache clearing\n    print("\nTesting cache clearing...")\n    dataloader.clear_caches()\n    print("Caches cleared successfully")\n    \n    print("\nOptimized Data Pipeline test completed successfully!")\n\n\nif __name__ == "__main__":\n    test_optimized_pipeline()