"""\nAdvanced Context Manager System for Memory Resource Management\n\nThis module implements comprehensive context managers for proper resource allocation\nand deallocation, preventing memory leaks and ensuring cleanup in all scenarios.\n"""\n\nimport threading\nfrom contextlib import contextmanager\nfrom typing import Dict, Optional, Any, Type, Tuple, Union, Callable\nfrom dataclasses import dataclass\nfrom enum import Enum\nimport logging\nimport weakref\nfrom types import TracebackType\n\n# Import from existing modules\ntry:\nfrom memory_management.advanced_memory_pooling_system import AdvancedMemoryPoolingSystem, MemoryBlock, TensorType\nexcept ImportError:\n    # Fallback for when this module is run directly\n    from advanced_memory_pooling_system import AdvancedMemoryPoolingSystem, MemoryBlock, TensorType\n\ntry:\nfrom memory_management.advanced_memory_management_vl import AdvancedMemoryPool, MemoryPoolType, VisionLanguageMemoryOptimizer\n        AdvancedMemoryPool,\n        MemoryPoolType,\n        VisionLanguageMemoryOptimizer\n    )\nexcept ImportError:\n    # Fallback for when this module is run directly\n    from advanced_memory_management_vl import (\n        AdvancedMemoryPool,\n        MemoryPoolType,\n        VisionLanguageMemoryOptimizer\n    )\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass ResourceState(Enum):\n    """Enumeration for resource allocation states"""\n    UNALLOCATED = "unallocated"\n    ALLOCATED = "allocated"\n    DEALLOCATING = "deallocating"\n    DEALLOCATED = "deallocated"\n    ERROR = "error"\n\n\n@dataclass\nclass ResourceInfo:\n    """Information about a managed resource"""\n    resource_id: str\n    resource_type: str\n    allocation_params: Dict[str, Any]\n    state: ResourceState\n    allocator_ref: Optional[weakref.ReferenceType] = None\n    cleanup_func: Optional[Callable[[], None]] = None\n    thread_id: Optional[int] = None\n    allocation_time: Optional[float] = None\n    deallocation_time: Optional[float] = None\n\n\nclass ResourceTracker:\n    """Thread-safe resource tracker to monitor allocations and prevent leaks"""\n    \n    def __init__(self):\n        self._resources: Dict[str, ResourceInfo] = {}\n        self._lock = threading.RLock()\n        self._cleanup_callbacks: Dict[str, Callable[[], None]] = {}\n    \n    def register_resource(self, resource_info: ResourceInfo) -> None:\n        """Register a resource for tracking"""\n        with self._lock:\n            self._resources[resource_info.resource_id] = resource_info\n    \n    def unregister_resource(self, resource_id: str) -> Optional[ResourceInfo]:\n        """Unregister a resource from tracking"""\n        with self._lock:\n            return self._resources.pop(resource_id, None)\n    \n    def get_resource(self, resource_id: str) -> Optional[ResourceInfo]:\n        """Get resource information"""\n        with self._lock:\n            return self._resources.get(resource_id)\n    \n    def update_resource_state(self, resource_id: str, new_state: ResourceState) -> bool:\n        """Update the state of a tracked resource"""\n        with self._lock:\n            if resource_id in self._resources:\n                self._resources[resource_id].state = new_state\n                return True\n            return False\n    \n    def get_active_resources(self) -> Dict[str, ResourceInfo]:\n        """Get all currently allocated resources"""\n        with self._lock:\n            return {\n                rid: rinfo for rid, rinfo in self._resources.items()\n                if rinfo.state in [ResourceState.ALLOCATED, ResourceState.DEALLOCATING]\n            }\n    \n    def cleanup_all_resources(self) -> int:\n        """Force cleanup of all tracked resources, return count of cleaned resources"""\n        with self._lock:\n            active_resources = self.get_active_resources()\n            cleaned_count = 0\n            \n            for resource_id, resource_info in active_resources.items():\n                try:\n                    if resource_info.cleanup_func:\n                        resource_info.cleanup_func()\n                    self.update_resource_state(resource_id, ResourceState.DEALLOCATED)\n                    cleaned_count += 1\n                except Exception as e:\n                    logger.error(f"Error cleaning up resource {resource_id}: {e}")\n            \n            # Remove cleaned resources from tracking\n            for resource_id in active_resources:\n                self.unregister_resource(resource_id)\n            \n            return cleaned_count\n\n\n# Global resource tracker\nresource_tracker = ResourceTracker()\n\n\nclass MemoryResourceContextManager:\n    """\n    General-purpose Memory Resource Context Manager that can wrap around\n    existing allocation/deallocation patterns\n    """\n    \n    def __init__(self,\n                 allocator_func: Callable[..., Any],\n                 deallocator_func: Callable[..., Any],\n                 resource_id: str,\n                 *args,\n                 **kwargs):\n        """\n        Initialize the context manager\n        \n        Args:\n            allocator_func: Function to call for allocation\n            deallocator_func: Function to call for deallocation\n            resource_id: Unique identifier for this resource\n            *args: Arguments for allocator function\n            **kwargs: Keyword arguments for allocator function\n        """\n        self.allocator_func = allocator_func\n        self.deallocator_func = deallocator_func\n        self.resource_id = resource_id\n        self.alloc_args = args\n        self.alloc_kwargs = kwargs\n        self.allocated_resource = None\n        self._entered = False\n        self._exited = False\n        self._exception_occurred = False\n        \n        # Register resource with tracker\n        resource_info = ResourceInfo(\n            resource_id=resource_id,\n            resource_type="generic",\n            allocation_params={"args": args, "kwargs": kwargs},\n            state=ResourceState.UNALLOCATED,\n            cleanup_func=self._cleanup,\n            thread_id=threading.get_ident()\n        )\n        resource_tracker.register_resource(resource_info)\n    \n    def __enter__(self):\n        """Enter the context and allocate resources"""\n        if self._entered:\n            raise RuntimeError("Context manager already entered")\n        \n        self._entered = True\n        \n        try:\n            # Update state to allocating\n            resource_tracker.update_resource_state(self.resource_id, ResourceState.ALLOCATED)\n            \n            # Perform allocation\n            self.allocated_resource = self.allocator_func(*self.alloc_args, **self.alloc_kwargs)\n            \n            return self.allocated_resource\n        except Exception as e:\n            # Update state to error if allocation failed\n            resource_tracker.update_resource_state(self.resource_id, ResourceState.ERROR)\n            logger.error(f"Error during resource allocation for {self.resource_id}: {e}")\n            raise\n    \n    def __exit__(self, exc_type: Optional[Type[BaseException]],\n                 exc_value: Optional[BaseException],\n                 traceback: Optional[TracebackType]) -> bool:\n        """Exit the context and deallocate resources"""\n        if self._exited:\n            # Already exited, nothing to do\n            return False\n\n        self._exited = True\n        self._exception_occurred = exc_type is not None\n\n        try:\n            # Update state to deallocating\n            resource_tracker.update_resource_state(self.resource_id, ResourceState.DEALLOCATING)\n\n            # Perform cleanup\n            if self.allocated_resource is not None:\n                self.deallocator_func(self.allocated_resource)\n\n            # Update state to deallocated\n            resource_tracker.update_resource_state(self.resource_id, ResourceState.DEALLOCATED)\n\n            # Unregister resource from tracker\n            resource_tracker.unregister_resource(self.resource_id)\n\n            # Log if exception occurred during context\n            if self._exception_occurred:\n                logger.warning(f"Exception occurred in context for resource {self.resource_id}: {exc_type.__name__}")\n\n            return False  # Don't suppress exceptions\n        except Exception as e:\n            # Update state to error if deallocation failed\n            resource_tracker.update_resource_state(self.resource_id, ResourceState.ERROR)\n            logger.error(f"Error during resource deallocation for {self.resource_id}: {e}")\n            raise\n    \n    def _cleanup(self):\n        """Internal cleanup function for forced cleanup"""\n        if self.allocated_resource is not None and not self._exited:\n            try:\n                self.deallocator_func(self.allocated_resource)\n                self.allocated_resource = None\n            except Exception as e:\n                logger.error(f"Error during forced cleanup of resource {self.resource_id}: {e}")\n\n\nclass KVCacheContextManager:\n    """\n    Specialized context manager for KV cache memory allocation\n    """\n    \n    def __init__(self, \n                 memory_system: AdvancedMemoryPoolingSystem,\n                 size: int,\n                 tensor_id: str,\n                 tensor_type: TensorType = TensorType.KV_CACHE):\n        self.memory_system = memory_system\n        self.size = size\n        self.tensor_id = tensor_id\n        self.tensor_type = tensor_type\n        self.allocated_block: Optional[MemoryBlock] = None\n        self._entered = False\n        self._exited = False\n        \n        # Register resource with tracker\n        resource_info = ResourceInfo(\n            resource_id=f"kv_cache_{tensor_id}",\n            resource_type="kv_cache",\n            allocation_params={"size": size, "tensor_type": tensor_type},\n            state=ResourceState.UNALLOCATED,\n            allocator_ref=weakref.ref(memory_system),\n            cleanup_func=self._cleanup,\n            thread_id=threading.get_ident()\n        )\n        resource_tracker.register_resource(resource_info)\n    \n    def __enter__(self) -> MemoryBlock:\n        """Allocate KV cache memory"""\n        if self._entered:\n            raise RuntimeError("KVCacheContextManager already entered")\n        \n        self._entered = True\n        \n        try:\n            # Update state to allocating\n            resource_tracker.update_resource_state(f"kv_cache_{self.tensor_id}", ResourceState.ALLOCATED)\n            \n            # Allocate memory block\n            self.allocated_block = self.memory_system.allocate(\n                self.tensor_type, \n                self.size, \n                self.tensor_id\n            )\n            \n            if self.allocated_block is None:\n                raise RuntimeError(f"Failed to allocate KV cache memory for tensor {self.tensor_id}")\n            \n            return self.allocated_block\n        except Exception as e:\n            # Update state to error if allocation failed\n            resource_tracker.update_resource_state(f"kv_cache_{self.tensor_id}", ResourceState.ERROR)\n            logger.error(f"Error during KV cache allocation for {self.tensor_id}: {e}")\n            raise\n    \n    def __exit__(self, exc_type: Optional[Type[BaseException]],\n                 exc_value: Optional[BaseException],\n                 traceback: Optional[TracebackType]) -> bool:\n        """Deallocate KV cache memory"""\n        if self._exited:\n            return False\n\n        self._exited = True\n\n        try:\n            # Update state to deallocating\n            resource_tracker.update_resource_state(f"kv_cache_{self.tensor_id}", ResourceState.DEALLOCATING)\n\n            # Deallocate memory block if it was allocated\n            if self.allocated_block is not None:\n                success = self.memory_system.deallocate(self.tensor_type, self.tensor_id)\n                if not success:\n                    logger.warning(f"Failed to deallocate KV cache for tensor {self.tensor_id}")\n\n            # Update state to deallocated\n            resource_tracker.update_resource_state(f"kv_cache_{self.tensor_id}", ResourceState.DEALLOCATED)\n\n            # Unregister resource from tracker\n            resource_tracker.unregister_resource(f"kv_cache_{self.tensor_id}")\n\n            return False  # Don't suppress exceptions\n        except Exception as e:\n            # Update state to error if deallocation failed\n            resource_tracker.update_resource_state(f"kv_cache_{self.tensor_id}", ResourceState.ERROR)\n            logger.error(f"Error during KV cache deallocation for {self.tensor_id}: {e}")\n            raise\n    \n    def _cleanup(self):\n        """Internal cleanup function for forced cleanup"""\n        if self.allocated_block is not None and not self._exited:\n            try:\n                self.memory_system.deallocate(self.tensor_type, self.tensor_id)\n                self.allocated_block = None\n            except Exception as e:\n                logger.error(f"Error during forced cleanup of KV cache {self.tensor_id}: {e}")\n\n\nclass ImageFeaturesContextManager:\n    """\n    Specialized context manager for image features memory allocation\n    """\n    \n    def __init__(self, \n                 memory_system: AdvancedMemoryPoolingSystem,\n                 size: int,\n                 tensor_id: str,\n                 tensor_type: TensorType = TensorType.IMAGE_FEATURES):\n        self.memory_system = memory_system\n        self.size = size\n        self.tensor_id = tensor_id\n        self.tensor_type = tensor_type\n        self.allocated_block: Optional[MemoryBlock] = None\n        self._entered = False\n        self._exited = False\n        \n        # Register resource with tracker\n        resource_info = ResourceInfo(\n            resource_id=f"image_features_{tensor_id}",\n            resource_type="image_features",\n            allocation_params={"size": size, "tensor_type": tensor_type},\n            state=ResourceState.UNALLOCATED,\n            allocator_ref=weakref.ref(memory_system),\n            cleanup_func=self._cleanup,\n            thread_id=threading.get_ident()\n        )\n        resource_tracker.register_resource(resource_info)\n    \n    def __enter__(self) -> MemoryBlock:\n        """Allocate image features memory"""\n        if self._entered:\n            raise RuntimeError("ImageFeaturesContextManager already entered")\n        \n        self._entered = True\n        \n        try:\n            # Update state to allocating\n            resource_tracker.update_resource_state(f"image_features_{self.tensor_id}", ResourceState.ALLOCATED)\n            \n            # Allocate memory block\n            self.allocated_block = self.memory_system.allocate(\n                self.tensor_type, \n                self.size, \n                self.tensor_id\n            )\n            \n            if self.allocated_block is None:\n                raise RuntimeError(f"Failed to allocate image features memory for tensor {self.tensor_id}")\n            \n            return self.allocated_block\n        except Exception as e:\n            # Update state to error if allocation failed\n            resource_tracker.update_resource_state(f"image_features_{self.tensor_id}", ResourceState.ERROR)\n            logger.error(f"Error during image features allocation for {self.tensor_id}: {e}")\n            raise\n    \n    def __exit__(self, exc_type: Optional[Type[BaseException]],\n                 exc_value: Optional[BaseException],\n                 traceback: Optional[TracebackType]) -> bool:\n        """Deallocate image features memory"""\n        if self._exited:\n            return False\n\n        self._exited = True\n\n        try:\n            # Update state to deallocating\n            resource_tracker.update_resource_state(f"image_features_{self.tensor_id}", ResourceState.DEALLOCATING)\n\n            # Deallocate memory block if it was allocated\n            if self.allocated_block is not None:\n                success = self.memory_system.deallocate(self.tensor_type, self.tensor_id)\n                if not success:\n                    logger.warning(f"Failed to deallocate image features for tensor {self.tensor_id}")\n\n            # Update state to deallocated\n            resource_tracker.update_resource_state(f"image_features_{self.tensor_id}", ResourceState.DEALLOCATED)\n\n            # Unregister resource from tracker\n            resource_tracker.unregister_resource(f"image_features_{self.tensor_id}")\n\n            return False  # Don't suppress exceptions\n        except Exception as e:\n            # Update state to error if deallocation failed\n            resource_tracker.update_resource_state(f"image_features_{self.tensor_id}", ResourceState.ERROR)\n            logger.error(f"Error during image features deallocation for {self.tensor_id}: {e}")\n            raise\n    \n    def _cleanup(self):\n        """Internal cleanup function for forced cleanup"""\n        if self.allocated_block is not None and not self._exited:\n            try:\n                self.memory_system.deallocate(self.tensor_type, self.tensor_id)\n                self.allocated_block = None\n            except Exception as e:\n                logger.error(f"Error during forced cleanup of image features {self.tensor_id}: {e}")\n\n\nclass TextEmbeddingsContextManager:\n    """\n    Specialized context manager for text embeddings memory allocation\n    """\n    \n    def __init__(self, \n                 memory_system: AdvancedMemoryPoolingSystem,\n                 size: int,\n                 tensor_id: str,\n                 tensor_type: TensorType = TensorType.TEXT_EMBEDDINGS):\n        self.memory_system = memory_system\n        self.size = size\n        self.tensor_id = tensor_id\n        self.tensor_type = tensor_type\n        self.allocated_block: Optional[MemoryBlock] = None\n        self._entered = False\n        self._exited = False\n        \n        # Register resource with tracker\n        resource_info = ResourceInfo(\n            resource_id=f"text_embeddings_{tensor_id}",\n            resource_type="text_embeddings",\n            allocation_params={"size": size, "tensor_type": tensor_type},\n            state=ResourceState.UNALLOCATED,\n            allocator_ref=weakref.ref(memory_system),\n            cleanup_func=self._cleanup,\n            thread_id=threading.get_ident()\n        )\n        resource_tracker.register_resource(resource_info)\n    \n    def __enter__(self) -> MemoryBlock:\n        """Allocate text embeddings memory"""\n        if self._entered:\n            raise RuntimeError("TextEmbeddingsContextManager already entered")\n        \n        self._entered = True\n        \n        try:\n            # Update state to allocating\n            resource_tracker.update_resource_state(f"text_embeddings_{self.tensor_id}", ResourceState.ALLOCATED)\n            \n            # Allocate memory block\n            self.allocated_block = self.memory_system.allocate(\n                self.tensor_type, \n                self.size, \n                self.tensor_id\n            )\n            \n            if self.allocated_block is None:\n                raise RuntimeError(f"Failed to allocate text embeddings memory for tensor {self.tensor_id}")\n            \n            return self.allocated_block\n        except Exception as e:\n            # Update state to error if allocation failed\n            resource_tracker.update_resource_state(f"text_embeddings_{self.tensor_id}", ResourceState.ERROR)\n            logger.error(f"Error during text embeddings allocation for {self.tensor_id}: {e}")\n            raise\n    \n    def __exit__(self, exc_type: Optional[Type[BaseException]],\n                 exc_value: Optional[BaseException],\n                 traceback: Optional[TracebackType]) -> bool:\n        """Deallocate text embeddings memory"""\n        if self._exited:\n            return False\n\n        self._exited = True\n\n        try:\n            # Update state to deallocating\n            resource_tracker.update_resource_state(f"text_embeddings_{self.tensor_id}", ResourceState.DEALLOCATING)\n\n            # Deallocate memory block if it was allocated\n            if self.allocated_block is not None:\n                success = self.memory_system.deallocate(self.tensor_type, self.tensor_id)\n                if not success:\n                    logger.warning(f"Failed to deallocate text embeddings for tensor {self.tensor_id}")\n\n            # Update state to deallocated\n            resource_tracker.update_resource_state(f"text_embeddings_{self.tensor_id}", ResourceState.DEALLOCATED)\n\n            # Unregister resource from tracker\n            resource_tracker.unregister_resource(f"text_embeddings_{self.tensor_id}")\n\n            return False  # Don't suppress exceptions\n        except Exception as e:\n            # Update state to error if deallocation failed\n            resource_tracker.update_resource_state(f"text_embeddings_{self.tensor_id}", ResourceState.ERROR)\n            logger.error(f"Error during text embeddings deallocation for {self.tensor_id}: {e}")\n            raise\n    \n    def _cleanup(self):\n        """Internal cleanup function for forced cleanup"""\n        if self.allocated_block is not None and not self._exited:\n            try:\n                self.memory_system.deallocate(self.tensor_type, self.tensor_id)\n                self.allocated_block = None\n            except Exception as e:\n                logger.error(f"Error during forced cleanup of text embeddings {self.tensor_id}: {e}")\n\n\nclass AdvancedMemoryPoolContextManager:\n    """\n    Context manager for AdvancedMemoryPool allocations\n    """\n    \n    def __init__(self, \n                 memory_pool: AdvancedMemoryPool,\n                 size: int,\n                 pool_type: MemoryPoolType = MemoryPoolType.TEMPORARY,\n                 alignment: Optional[int] = None):\n        self.memory_pool = memory_pool\n        self.size = size\n        self.pool_type = pool_type\n        self.alignment = alignment\n        self.allocated_ptr = None\n        self.allocated_size = None\n        self._entered = False\n        self._exited = False\n        \n        # Generate a unique resource ID\n        import time\n        self.resource_id = f"pool_{id(memory_pool)}_{int(time.time() * 1000000)}"\n        \n        # Register resource with tracker\n        resource_info = ResourceInfo(\n            resource_id=self.resource_id,\n            resource_type="memory_pool",\n            allocation_params={\n                "size": size, \n                "pool_type": pool_type, \n                "alignment": alignment\n            },\n            state=ResourceState.UNALLOCATED,\n            allocator_ref=weakref.ref(memory_pool),\n            cleanup_func=self._cleanup,\n            thread_id=threading.get_ident()\n        )\n        resource_tracker.register_resource(resource_info)\n    \n    def __enter__(self) -> Tuple[int, int]:\n        """Allocate memory from the pool"""\n        if self._entered:\n            raise RuntimeError("AdvancedMemoryPoolContextManager already entered")\n\n        self._entered = True\n\n        try:\n            # Update state to allocating\n            resource_tracker.update_resource_state(self.resource_id, ResourceState.ALLOCATED)\n\n            # Allocate memory from pool\n            result: Optional[Tuple[int, int]] = self.memory_pool.allocate(\n                self.size,\n                self.pool_type,\n                self.alignment\n            )\n\n            if result is None:\n                raise RuntimeError(f"Failed to allocate {self.size} bytes from memory pool")\n\n            self.allocated_ptr, self.allocated_size = result\n            return self.allocated_ptr, self.allocated_size\n        except Exception as e:\n            # Update state to error if allocation failed\n            resource_tracker.update_resource_state(self.resource_id, ResourceState.ERROR)\n            logger.error(f"Error during memory pool allocation: {e}")\n            raise\n    \n    def __exit__(self, exc_type: Optional[Type[BaseException]],\n                 exc_value: Optional[BaseException],\n                 traceback: Optional[TracebackType]) -> bool:\n        """Deallocate memory back to the pool"""\n        if self._exited:\n            return False\n\n        self._exited = True\n\n        try:\n            # Update state to deallocating\n            resource_tracker.update_resource_state(self.resource_id, ResourceState.DEALLOCATING)\n\n            # Deallocate memory if it was allocated\n            if self.allocated_ptr is not None:\n                success = self.memory_pool.deallocate(self.allocated_ptr)\n                if not success:\n                    logger.warning(f"Failed to deallocate memory at {hex(self.allocated_ptr)}")\n\n            # Update state to deallocated\n            resource_tracker.update_resource_state(self.resource_id, ResourceState.DEALLOCATED)\n\n            # Unregister resource from tracker\n            resource_tracker.unregister_resource(self.resource_id)\n\n            return False  # Don't suppress exceptions\n        except Exception as e:\n            # Update state to error if deallocation failed\n            resource_tracker.update_resource_state(self.resource_id, ResourceState.ERROR)\n            logger.error(f"Error during memory pool deallocation: {e}")\n            raise\n    \n    def _cleanup(self):\n        """Internal cleanup function for forced cleanup"""\n        if self.allocated_ptr is not None and not self._exited:\n            try:\n                self.memory_pool.deallocate(self.allocated_ptr)\n                self.allocated_ptr = None\n            except Exception as e:\n                logger.error(f"Error during forced cleanup of memory pool allocation: {e}")\n\n\nclass VisionLanguageMemoryOptimizerContextManager:\n    """\n    Context manager for VisionLanguageMemoryOptimizer tensor allocations\n    """\n    \n    def __init__(self, \n                 optimizer: VisionLanguageMemoryOptimizer,\n                 shape: Tuple[int, ...],\n                 dtype: Any,\n                 tensor_type: str = "general"):\n        self.optimizer = optimizer\n        self.shape = shape\n        self.dtype = dtype\n        self.tensor_type = tensor_type\n        self.allocated_tensor = None\n        self._entered = False\n        self._exited = False\n        \n        # Generate a unique resource ID\n        import time\n        self.resource_id = f"vl_tensor_{id(optimizer)}_{int(time.time() * 1000000)}"\n        \n        # Register resource with tracker\n        resource_info = ResourceInfo(\n            resource_id=self.resource_id,\n            resource_type="vl_tensor",\n            allocation_params={\n                "shape": shape, \n                "dtype": str(dtype), \n                "tensor_type": tensor_type\n            },\n            state=ResourceState.UNALLOCATED,\n            allocator_ref=weakref.ref(optimizer),\n            cleanup_func=self._cleanup,\n            thread_id=threading.get_ident()\n        )\n        resource_tracker.register_resource(resource_info)\n    \n    def __enter__(self):\n        """Allocate tensor with optimization"""\n        if self._entered:\n            raise RuntimeError("VisionLanguageMemoryOptimizerContextManager already entered")\n        \n        self._entered = True\n        \n        try:\n            # Update state to allocating\n            resource_tracker.update_resource_state(self.resource_id, ResourceState.ALLOCATED)\n            \n            # Allocate optimized tensor\n            self.allocated_tensor = self.optimizer.allocate_tensor_memory(\n                self.shape, \n                self.dtype, \n                self.tensor_type\n            )\n            \n            if self.allocated_tensor is None:\n                raise RuntimeError(f"Failed to allocate optimized tensor with shape {self.shape}")\n            \n            return self.allocated_tensor\n        except Exception as e:\n            # Update state to error if allocation failed\n            resource_tracker.update_resource_state(self.resource_id, ResourceState.ERROR)\n            logger.error(f"Error during optimized tensor allocation: {e}")\n            raise\n    \n    def __exit__(self, exc_type: Optional[Type[BaseException]],\n                 exc_value: Optional[BaseException],\n                 traceback: Optional[TracebackType]) -> bool:\n        """Free tensor memory"""\n        if self._exited:\n            return False\n\n        self._exited = True\n\n        try:\n            # Update state to deallocating\n            resource_tracker.update_resource_state(self.resource_id, ResourceState.DEALLOCATING)\n\n            # Free tensor memory if it was allocated\n            if self.allocated_tensor is not None:\n                self.optimizer.free_tensor_memory(self.allocated_tensor, self.tensor_type)\n\n            # Update state to deallocated\n            resource_tracker.update_resource_state(self.resource_id, ResourceState.DEALLOCATED)\n\n            # Unregister resource from tracker\n            resource_tracker.unregister_resource(self.resource_id)\n\n            return False  # Don't suppress exceptions\n        except Exception as e:\n            # Update state to error if deallocation failed\n            resource_tracker.update_resource_state(self.resource_id, ResourceState.ERROR)\n            logger.error(f"Error during optimized tensor deallocation: {e}")\n            raise\n    \n    def _cleanup(self):\n        """Internal cleanup function for forced cleanup"""\n        if self.allocated_tensor is not None and not self._exited:\n            try:\n                self.optimizer.free_tensor_memory(self.allocated_tensor, self.tensor_type)\n                self.allocated_tensor = None\n            except Exception as e:\n                logger.error(f"Error during forced cleanup of optimized tensor: {e}")\n\n\n# Context manager factory functions\n@contextmanager\ndef memory_resource_context(allocator_func: Callable[..., Any],\n                           deallocator_func: Callable[..., Any],\n                           resource_id: str,\n                           *args, **kwargs):\n    """\n    Context manager factory function for generic resource allocation\n    \n    Args:\n        allocator_func: Function to call for allocation\n        deallocator_func: Function to call for deallocation\n        resource_id: Unique identifier for this resource\n        *args: Arguments for allocator function\n        **kwargs: Keyword arguments for allocator function\n    """\n    ctx = MemoryResourceContextManager(allocator_func, deallocator_func, resource_id, *args, **kwargs)\n    try:\n        yield ctx.__enter__()\n    finally:\n        ctx.__exit__(None, None, None)\n\n\n@contextmanager\ndef kv_cache_context(memory_system: AdvancedMemoryPoolingSystem,\n                     size: int,\n                     tensor_id: str,\n                     tensor_type: TensorType = TensorType.KV_CACHE):\n    """\n    Context manager factory for KV cache allocation\n    \n    Args:\n        memory_system: AdvancedMemoryPoolingSystem instance\n        size: Size to allocate in bytes\n        tensor_id: Unique ID for the tensor\n        tensor_type: Type of tensor (default: KV_CACHE)\n    """\n    ctx = KVCacheContextManager(memory_system, size, tensor_id, tensor_type)\n    try:\n        yield ctx.__enter__()\n    finally:\n        ctx.__exit__(None, None, None)\n\n\n@contextmanager\ndef image_features_context(memory_system: AdvancedMemoryPoolingSystem,\n                           size: int,\n                           tensor_id: str,\n                           tensor_type: TensorType = TensorType.IMAGE_FEATURES):\n    """\n    Context manager factory for image features allocation\n    \n    Args:\n        memory_system: AdvancedMemoryPoolingSystem instance\n        size: Size to allocate in bytes\n        tensor_id: Unique ID for the tensor\n        tensor_type: Type of tensor (default: IMAGE_FEATURES)\n    """\n    ctx = ImageFeaturesContextManager(memory_system, size, tensor_id, tensor_type)\n    try:\n        yield ctx.__enter__()\n    finally:\n        ctx.__exit__(None, None, None)\n\n\n@contextmanager\ndef text_embeddings_context(memory_system: AdvancedMemoryPoolingSystem,\n                            size: int,\n                            tensor_id: str,\n                            tensor_type: TensorType = TensorType.TEXT_EMBEDDINGS):\n    """\n    Context manager factory for text embeddings allocation\n    \n    Args:\n        memory_system: AdvancedMemoryPoolingSystem instance\n        size: Size to allocate in bytes\n        tensor_id: Unique ID for the tensor\n        tensor_type: Type of tensor (default: TEXT_EMBEDDINGS)\n    """\n    ctx = TextEmbeddingsContextManager(memory_system, size, tensor_id, tensor_type)\n    try:\n        yield ctx.__enter__()\n    finally:\n        ctx.__exit__(None, None, None)\n\n\n@contextmanager\ndef memory_pool_context(memory_pool: AdvancedMemoryPool,\n                        size: int,\n                        pool_type: MemoryPoolType = MemoryPoolType.TEMPORARY,\n                        alignment: Optional[int] = None):\n    """\n    Context manager factory for memory pool allocation\n    \n    Args:\n        memory_pool: AdvancedMemoryPool instance\n        size: Size to allocate in bytes\n        pool_type: Type of memory pool (default: TEMPORARY)\n        alignment: Memory alignment requirement (default: None)\n    """\n    ctx = AdvancedMemoryPoolContextManager(memory_pool, size, pool_type, alignment)\n    try:\n        yield ctx.__enter__()\n    finally:\n        ctx.__exit__(None, None, None)\n\n\n@contextmanager\ndef vl_tensor_context(optimizer: VisionLanguageMemoryOptimizer,\n                      shape: Tuple[int, ...],\n                      dtype: Any,\n                      tensor_type: str = "general"):\n    """\n    Context manager factory for vision-language optimized tensor allocation\n    \n    Args:\n        optimizer: VisionLanguageMemoryOptimizer instance\n        shape: Shape of the tensor\n        dtype: Data type of the tensor\n        tensor_type: Type of tensor ('general', 'kv_cache', 'image_features', 'text_embeddings')\n    """\n    ctx = VisionLanguageMemoryOptimizerContextManager(optimizer, shape, dtype, tensor_type)\n    try:\n        yield ctx.__enter__()\n    finally:\n        ctx.__exit__(None, None, None)\n\n\n# Thread-safe cleanup function\ndef cleanup_all_resources():\n    """\n    Force cleanup of all tracked resources across all threads.\n    This is especially useful for preventing memory leaks when\n    context managers are not properly exited.\n    """\n    cleaned_count = resource_tracker.cleanup_all_resources()\n    logger.info(f"Cleaned up {cleaned_count} resources that were not properly deallocated")\n    return cleaned_count\n\n\n# Atexit handler to ensure cleanup on program exit\nimport atexit\natexit.register(cleanup_all_resources)