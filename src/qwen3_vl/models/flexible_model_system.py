"""\nComprehensive flexible model system that integrates all components.\n\nThis module brings together the model registry, configuration management, \nmemory management, model loading, hardware optimization, plugin system,\noptimization strategies, performance optimization, configuration validation,\nand model adapter layer into a unified system.\n"""\n\nimport torch\nimport torch.nn as nn\nfrom typing import Dict, Optional, Any, Union, List\nfrom pathlib import Path\nimport logging\n\n# Import all the components\nfrom models.model_registry import ModelRegistry, ModelFactory, get_model_registry\nfrom models.config_manager import ConfigManager, get_config_manager\nfrom models.adaptive_memory_manager import AdaptiveMemoryManager, get_memory_manager\nfrom models.model_loader import ModelLoader, get_model_loader\nfrom models.hardware_optimizer import HardwareOptimizer, get_hardware_optimizer\nfrom models.plugin_system import ModelPluginManager, get_plugin_manager\nfrom models.optimization_strategies import OptimizationManager, get_optimization_manager\nfrom models.performance_optimizer import PerformanceOptimizer, get_performance_optimizer\nfrom models.config_validator import ConfigValidator, get_config_validator\nfrom models.model_adapter import UnifiedModelInterface, create_unified_interface\n\n\nclass FlexibleModelSystem:\n    """\n    Comprehensive system that integrates all model management components.\n    """\n    \n    def __init__(self):\n        self._logger = logging.getLogger(f"{self.__class__.__module__}.{self.__class__.__name__}")\n        \n        # Initialize all components\n        self.model_registry = get_model_registry()\n        self.config_manager = get_config_manager()\n        self.memory_manager = get_memory_manager()\n        self.model_loader = get_model_loader()\n        self.hardware_optimizer = get_hardware_optimizer()\n        self.plugin_manager = get_plugin_manager()\n        self.optimization_manager = get_optimization_manager()\n        self.performance_optimizer = get_performance_optimizer()\n        self.config_validator = get_config_validator()\n        \n        self.model_factory = ModelFactory(self.model_registry)\n    \n    def register_model(\n        self,\n        name: str,\n        model_class: type,\n        config_class: type,\n        adapter_class: Optional[type] = None,\n        supported_dtypes: List[str] = None,\n        required_memory_gb: float = 8.0,\n        max_sequence_length: int = 2048,\n        description: str = "",\n        model_type: str = "language"\n    ) -> bool:\n        """\n        Register a model in the system.\n        \n        Args:\n            name: Name of the model\n            model_class: Model class\n            config_class: Configuration class\n            adapter_class: Adapter class (optional)\n            supported_dtypes: List of supported data types\n            required_memory_gb: Required memory in GB\n            max_sequence_length: Maximum sequence length\n            description: Model description\n            model_type: Type of model\n            \n        Returns:\n            True if registration was successful, False otherwise\n        """\nfrom models.model_registry import ModelSpec\n        \n        if supported_dtypes is None:\n            supported_dtypes = ["float16", "float32", "bfloat16"]\n        \n        model_spec = ModelSpec(\n            name=name,\n            model_class=model_class,\n            config_class=config_class,\n            adapter_class=adapter_class,\n            supported_dtypes=supported_dtypes,\n            required_memory_gb=required_memory_gb,\n            max_sequence_length=max_sequence_length,\n            description=description,\n            model_type=model_type\n        )\n        \n        return self.model_registry.register_model(model_spec)\n    \n    def load_model(\n        self,\n        model_name: str,\n        model_path: Optional[str] = None,\n        config: Optional[Dict[str, Any]] = None,\n        device_map: Optional[Union[str, Dict[str, Any]]] = None,\n        torch_dtype: Optional[Union[str, torch.dtype]] = None,\n        apply_optimizations: bool = True,\n        use_hardware_optimizations: bool = True,\n        validate_config: bool = True\n    ) -> UnifiedModelInterface:\n        """\n        Load a model with all applicable optimizations and configurations.\n        \n        Args:\n            model_name: Name of the model to load\n            model_path: Path to model (if loading from local)\n            model_path: Path to model (if different from model_name)\n            config: Configuration dictionary\n            device_map: Device mapping\n            torch_dtype: Data type for model\n            apply_optimizations: Whether to apply optimizations\n            use_hardware_optimizations: Whether to apply hardware optimizations\n            validate_config: Whether to validate configuration\n            \n        Returns:\n            UnifiedModelInterface instance\n        """\n        # Get model spec\n        model_spec = self.model_registry.get_model_spec(model_name)\n        if not model_spec:\n            raise ValueError(f"Model {model_name} is not registered")\n        \n        # Load configuration\n        if config is None:\n            config = {}\n        \n        # If model_path is not provided, use model_name as path (for HuggingFace models)\n        if model_path is None:\n            model_path = model_name\n        \n        # Load configuration\n        full_config = self.config_manager.load_config(model_name, config_dict=config)\n        \n        # Validate configuration\n        if validate_config:\n            errors = self.config_validator.validate_config(full_config, model_spec.model_type)\n            if errors:\n                for error in errors:\n                    if error.severity == "error":\n                        raise ValueError(f"Configuration validation error: {error.message}")\n                    else:\n                        self._logger.warning(f"Configuration validation warning: {error.message}")\n        \n        # Adapt configuration for hardware\n        system_memory = self.memory_manager.get_system_memory_info()\n        available_memory_gb = system_memory["available_gb"]\n        \n        adapted_config = self.config_manager.adapt_config_for_hardware(\n            full_config, available_memory_gb\n        )\n        \n        # Load the model\n        model = self.model_loader.load_model(\n            model_path,\n            model_spec.model_class,\n            model_spec.config_class,\n            config=adapted_config,\n            device_map=device_map,\n            torch_dtype=torch_dtype\n        )\n        \n        # Apply hardware optimizations\n        if use_hardware_optimizations:\n            profile = self.hardware_optimizer.get_optimization_profile(\n                model_name,\n                self.hardware_optimizer.get_model_size_category(model.num_parameters() if hasattr(model, 'num_parameters') else 0)\n            )\n            if profile:\n                model = self.hardware_optimizer.apply_optimizations(model, profile)\n        \n        # Apply performance optimizations\n        perf_config = self.performance_optimizer.get_performance_config(model_name)\n        if perf_config:\n            model, perf_settings = self.performance_optimizer.apply_performance_config(model, perf_config)\n            self._logger.info(f"Applied performance settings: {perf_settings}")\n        \n        # Apply model-specific optimizations\n        if apply_optimizations:\n            model = self.optimization_manager.apply_optimizations(model, model_name)\n        \n        # Create unified interface\n        unified_interface = create_unified_interface(model, model_spec.model_type, adapted_config)\n        \n        self._logger.info(f"Successfully loaded and optimized model: {model_name}")\n        return unified_interface\n    \n    def list_available_models(self) -> List[str]:\n        """List all available models in the system."""\n        return self.model_factory.list_available_models()\n    \n    def get_model_info(self, model_name: str) -> Optional[Dict[str, Any]]:\n        """Get information about a specific model."""\n        return self.model_factory.get_model_info(model_name)\n    \n    def load_plugins_from_directory(self, directory_path: str) -> bool:\n        """Load plugins from a directory."""\n        success = self.plugin_manager.load_plugins_from_directory(directory_path)\n        if success:\n            # Apply plugins to registry\n            self.plugin_manager.apply_plugins_to_registry()\n        return success\n    \n    def get_system_info(self) -> Dict[str, Any]:\n        """Get comprehensive system information."""\n        hardware_spec = self.hardware_optimizer.get_hardware_spec()\n        system_memory = self.memory_manager.get_system_memory_info()\n        gpu_memory = self.memory_manager.get_gpu_memory_info()\n        \n        return {\n            "hardware": {\n                "cpu_count": hardware_spec.cpu_count,\n                "cpu_architecture": hardware_spec.cpu_architecture,\n                "memory_gb": hardware_spec.memory_gb,\n                "gpu_count": hardware_spec.gpu_count,\n                "gpu_names": hardware_spec.gpu_names,\n                "cuda_available": hardware_spec.cuda_available,\n                "compute_capability": hardware_spec.compute_capability,\n            },\n            "system_memory": system_memory,\n            "gpu_memory": gpu_memory,\n            "available_models": self.list_available_models(),\n            "model_count": len(self.list_available_models())\n        }\n    \n    def get_optimization_recommendations(\n        self,\n        model_name: str,\n        hardware_memory_gb: Optional[float] = None,\n        target_performance: str = "balanced"\n    ) -> Dict[str, Any]:\n        """Get optimization recommendations for a model."""\n        if hardware_memory_gb is None:\n            system_memory = self.memory_manager.get_system_memory_info()\n            hardware_memory_gb = system_memory["available_gb"]\n        \n        recommendations = self.optimization_manager.get_optimization_recommendations(\n            model_name, hardware_memory_gb, target_performance\n        )\n        \n        return {\n            "model_name": model_name,\n            "hardware_memory_gb": hardware_memory_gb,\n            "target_performance": target_performance,\n            "recommendations": [rec.__dict__ for rec in recommendations],\n            "performance_config": self.performance_optimizer.calculate_performance_config(\n                1e9,  # Placeholder - in practice, get actual param count\n                hardware_memory_gb\n            ).__dict__\n        }\n\n\n# Global system instance\nflexible_model_system = FlexibleModelSystem()\n\n\ndef get_flexible_model_system() -> FlexibleModelSystem:\n    """\n    Get the global flexible model system instance.\n    \n    Returns:\n        FlexibleModelSystem instance\n    """\n    return flexible_model_system\n\n\n# Example usage and initialization\ndef initialize_system():\n    """Initialize the system with default configurations and models."""\n    # Register Qwen3-4B-Instruct-2507 model\n    try:\nfrom models.base_model import Qwen3VLModel\nfrom qwen3_vl.config.base_config import Qwen3VLConfig\n        \n        flexible_model_system.register_model(\n            name="Qwen3-4B-Instruct-2507",\n            model_class=Qwen3VLModel,\n            config_class=Qwen3VLConfig,\n            adapter_class=None,  # Will use default\n            supported_dtypes=["float16", "float32", "bfloat16"],\n            required_memory_gb=6.0,\n            max_sequence_length=32768,\n            description="Qwen3 4B Instruct model (2507 version)",\n            model_type="language"\n        )\n        \n        print("Successfully registered Qwen3-4B-Instruct-2507 model")\n    except ImportError as e:\n        print(f"Could not register Qwen3-4B-Instruct-2507: {e}")\n    \n    # Apply any loaded plugins to the registry\n    flexible_model_system.plugin_manager.apply_plugins_to_registry()\n\n\n# Initialize the system when module is imported\ninitialize_system()