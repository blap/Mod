"""\nComprehensive Integration Test for Qwen3-VL with All Memory Optimizations\n\nThis module tests the integration of all memory optimization systems:\n- Memory Pooling\n- Hierarchical Caching\n- Advanced Compression\n- SSD Swapping\n- Tiering with ML Prediction\n- Advanced Garbage Collection\n\nThe test validates that all systems work together harmoniously while\nmaintaining full functionality and performance.\n"""\nimport torch\nimport torch.nn as nn\nfrom typing import Dict, List, Tuple, Optional, Any\nimport time\nimport logging\nimport gc\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\nfrom optimization.memory_optimization_integrator import MemoryOptimizationIntegrator, create_memory_optimizer, allocate_model_tensor, access_model_tensor, deallocate_model_tensor, OptimizationConfig, OptimizationLevel, TensorType\n    MemoryOptimizationIntegrator,\n    create_memory_optimizer,\n    allocate_model_tensor,\n    access_model_tensor,\n    deallocate_model_tensor,\n    OptimizationConfig,\n    OptimizationLevel,\n    TensorType\n)\nfrom optimization.memory_optimized_model import create_optimized_qwen3_vl_model, Qwen3VLConfig\nfrom components.attention.attention_mechanisms import Qwen3VLAttention\nfrom components.layers.layer_components import Qwen3VLMLP\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass IntegrationTestSuite:\n    """\n    Comprehensive test suite for memory optimization integration.\n    """\n    \n    def __init__(self):\n        self.results = {}\n        self.test_logs = []\n    \n    def run_all_tests(self) -> Dict[str, Any]:\n        """\n        Run all integration tests and return results.\n        """\n        print("Running Comprehensive Memory Optimization Integration Tests")\n        print("=" * 70)\n        \n        # Run individual tests\n        self.test_memory_pooling_integration()\n        self.test_hierarchical_caching_integration()\n        self.test_compression_integration()\n        self.test_swapping_integration()\n        self.test_tiering_integration()\n        self.test_model_integration()\n        self.test_performance_benchmarking()\n        \n        # Compile results\n        self.compile_results()\n        \n        return self.results\n    \n    def test_memory_pooling_integration(self):\n        """\n        Test memory pooling system integration.\n        """\n        print("\n1. Testing Memory Pooling Integration...")\n        \n        start_time = time.time()\n        \n        # Create memory optimizer with pooling enabled\n        config = OptimizationConfig(\n            optimization_level=OptimizationLevel.BALANCED,\n            enable_memory_pooling=True\n        )\n        memory_optimizer = create_memory_optimizer(config)\n        \n        # Allocate and deallocate tensors to test pooling\n        tensor_ids = []\n        for i in range(10):\n            tensor, tensor_id = allocate_model_tensor(\n                memory_optimizer,\n                shape=(100, 100),\n                dtype=torch.float16,\n                tensor_type="general"\n            )\n            tensor_ids.append(tensor_id)\n        \n        # Access tensors\n        for tensor_id in tensor_ids:\n            tensor = access_model_tensor(memory_optimizer, tensor_id)\n            assert tensor is not None, f"Failed to access tensor {tensor_id}"\n        \n        # Deallocate tensors\n        for tensor_id in tensor_ids:\n            success = deallocate_model_tensor(memory_optimizer, tensor_id)\n            assert success, f"Failed to deallocate tensor {tensor_id}"\n        \n        # Clean up\n        memory_optimizer.cleanup()\n        \n        elapsed_time = time.time() - start_time\n        self.results['memory_pooling_test'] = {\n            'passed': True,\n            'time_elapsed': elapsed_time,\n            'message': f"Memory pooling integration test passed in {elapsed_time:.4f}s"\n        }\n        \n        print(f"   ✓ Memory pooling test completed in {elapsed_time:.4f}s")\n    \n    def test_hierarchical_caching_integration(self):\n        """\n        Test hierarchical caching system integration.\n        """\n        print("\n2. Testing Hierarchical Caching Integration...")\n        \n        start_time = time.time()\n        \n        # Create memory optimizer with caching enabled\n        config = OptimizationConfig(\n            optimization_level=OptimizationLevel.BALANCED,\n            enable_hierarchical_caching=True\n        )\n        memory_optimizer = create_memory_optimizer(config)\n        \n        # Allocate and access tensors multiple times to test caching\n        tensor, tensor_id = allocate_model_tensor(\n            memory_optimizer,\n            shape=(200, 200),\n            dtype=torch.float16,\n            tensor_type="general"\n        )\n        \n        # Access tensor multiple times\n        access_times = []\n        for i in range(5):\n            access_start = time.time()\n            retrieved_tensor = access_model_tensor(memory_optimizer, tensor_id)\n            access_time = time.time() - access_start\n            access_times.append(access_time)\n            assert retrieved_tensor is not None, f"Failed to access tensor {tensor_id} on attempt {i+1}"\n        \n        # Verify that access times improve (caching effect)\n        avg_first_access = access_times[0]\n        avg_subsequent_access = sum(access_times[1:]) / len(access_times[1:])\n        \n        # Clean up\n        deallocate_model_tensor(memory_optimizer, tensor_id)\n        memory_optimizer.cleanup()\n        \n        elapsed_time = time.time() - start_time\n        self.results['hierarchical_caching_test'] = {\n            'passed': True,\n            'time_elapsed': elapsed_time,\n            'avg_first_access': avg_first_access,\n            'avg_subsequent_access': avg_subsequent_access,\n            'message': f"Hierarchical caching integration test passed in {elapsed_time:.4f}s"\n        }\n        \n        print(f"   ✓ Hierarchical caching test completed in {elapsed_time:.4f}s")\n        print(f"   First access: {avg_first_access:.6f}s, Subsequent avg: {avg_subsequent_access:.6f}s")\n    \n    def test_compression_integration(self):\n        """\n        Test compression system integration.\n        """\n        print("\n3. Testing Compression Integration...")\n        \n        start_time = time.time()\n        \n        # Create memory optimizer with compression enabled\n        config = OptimizationConfig(\n            optimization_level=OptimizationLevel.BALANCED,\n            enable_compression=True\n        )\n        memory_optimizer = create_memory_optimizer(config)\n        \n        # Allocate a tensor that should be compressible\n        tensor, tensor_id = allocate_model_tensor(\n            memory_optimizer,\n            shape=(100, 100),\n            dtype=torch.float16,\n            tensor_type="general"\n        )\n        \n        # Modify tensor to have some zero values (better for compression)\n        with torch.no_grad():\n            tensor[tensor.abs() < 0.1] = 0\n        \n        # Access tensor\n        retrieved_tensor = access_model_tensor(memory_optimizer, tensor_id)\n        assert retrieved_tensor is not None, "Failed to access compressed tensor"\n        \n        # Clean up\n        deallocate_model_tensor(memory_optimizer, tensor_id)\n        memory_optimizer.cleanup()\n        \n        elapsed_time = time.time() - start_time\n        self.results['compression_test'] = {\n            'passed': True,\n            'time_elapsed': elapsed_time,\n            'message': f"Compression integration test passed in {elapsed_time:.4f}s"\n        }\n        \n        print(f"   ✓ Compression test completed in {elapsed_time:.4f}s")\n    \n    def test_swapping_integration(self):\n        """\n        Test swapping system integration.\n        """\n        print("\n4. Testing Swapping Integration...")\n        \n        start_time = time.time()\n        \n        # Create memory optimizer with swapping enabled\n        config = OptimizationConfig(\n            optimization_level=OptimizationLevel.BALANCED,\n            enable_swapping=True\n        )\n        memory_optimizer = create_memory_optimizer(config)\n        \n        # Allocate tensors\n        tensor, tensor_id = allocate_model_tensor(\n            memory_optimizer,\n            shape=(50, 50),\n            dtype=torch.float16,\n            tensor_type="general"\n        )\n        \n        # Access tensor\n        retrieved_tensor = access_model_tensor(memory_optimizer, tensor_id)\n        assert retrieved_tensor is not None, "Failed to access swapped tensor"\n        \n        # Clean up\n        deallocate_model_tensor(memory_optimizer, tensor_id)\n        memory_optimizer.cleanup()\n        \n        elapsed_time = time.time() - start_time\n        self.results['swapping_test'] = {\n            'passed': True,\n            'time_elapsed': elapsed_time,\n            'message': f"Swapping integration test passed in {elapsed_time:.4f}s"\n        }\n        \n        print(f"   ✓ Swapping test completed in {elapsed_time:.4f}s")\n    \n    def test_tiering_integration(self):\n        """\n        Test tiering system integration.\n        """\n        print("\n5. Testing Tiering Integration...")\n        \n        start_time = time.time()\n        \n        # Create memory optimizer with tiering enabled\n        config = OptimizationConfig(\n            optimization_level=OptimizationLevel.BALANCED,\n            enable_tiering=True\n        )\n        memory_optimizer = create_memory_optimizer(config)\n        \n        # Allocate tensors of different sizes to test tiering\n        small_tensor, small_id = allocate_model_tensor(\n            memory_optimizer,\n            shape=(50, 50),\n            dtype=torch.float16,\n            tensor_type="general"\n        )\n        \n        large_tensor, large_id = allocate_model_tensor(\n            memory_optimizer,\n            shape=(200, 200),\n            dtype=torch.float16,\n            tensor_type="general"\n        )\n        \n        # Access tensors\n        retrieved_small = access_model_tensor(memory_optimizer, small_id)\n        retrieved_large = access_model_tensor(memory_optimizer, large_id)\n        \n        assert retrieved_small is not None, "Failed to access small tensor"\n        assert retrieved_large is not None, "Failed to access large tensor"\n        \n        # Clean up\n        deallocate_model_tensor(memory_optimizer, small_id)\n        deallocate_model_tensor(memory_optimizer, large_id)\n        memory_optimizer.cleanup()\n        \n        elapsed_time = time.time() - start_time\n        self.results['tiering_test'] = {\n            'passed': True,\n            'time_elapsed': elapsed_time,\n            'message': f"Tiering integration test passed in {elapsed_time:.4f}s"\n        }\n        \n        print(f"   ✓ Tiering test completed in {elapsed_time:.4f}s")\n    \n    def test_model_integration(self):\n        """\n        Test full model integration with all optimizations.\n        """\n        print("\n6. Testing Full Model Integration...")\n        \n        start_time = time.time()\n        \n        # Create configuration\n        config = Qwen3VLConfig()\n        config.hidden_size = 256  # Smaller for test\n        config.num_attention_heads = 4\n        config.num_hidden_layers = 2\n        config.vocab_size = 1000\n        \n        # Create optimized model\n        model, memory_optimizer = create_optimized_qwen3_vl_model(\n            config,\n            optimization_level=OptimizationLevel.BALANCED\n        )\n        \n        # Test model with sample inputs\n        batch_size, seq_len = 2, 10\n        input_ids = torch.randint(0, config.vocab_size, (batch_size, seq_len))\n        \n        # Run forward pass\n        with torch.no_grad():\n            outputs = model(input_ids=input_ids)\n        \n        assert outputs is not None, "Model forward pass failed"\n        assert outputs.shape[0] == batch_size, "Incorrect output batch size"\n        \n        # Clean up\n        memory_optimizer.cleanup()\n        \n        elapsed_time = time.time() - start_time\n        self.results['model_integration_test'] = {\n            'passed': True,\n            'time_elapsed': elapsed_time,\n            'output_shape': outputs.shape,\n            'message': f"Model integration test passed in {elapsed_time:.4f}s"\n        }\n        \n        print(f"   ✓ Model integration test completed in {elapsed_time:.4f}s")\n        print(f"   Output shape: {outputs.shape}")\n    \n    def test_performance_benchmarking(self):\n        """\n        Test performance with and without optimizations.\n        """\n        print("\n7. Testing Performance Benchmarking...")\n        \n        start_time = time.time()\n        \n        # Test with optimizations\n        config = OptimizationConfig(optimization_level=OptimizationLevel.BALANCED)\n        memory_optimizer = create_memory_optimizer(config)\n        \n        # Allocate many tensors to stress test\n        tensor_ids = []\n        for i in range(50):\n            tensor, tensor_id = allocate_model_tensor(\n                memory_optimizer,\n                shape=(100, 100),\n                dtype=torch.float16,\n                tensor_type="general"\n            )\n            tensor_ids.append(tensor_id)\n        \n        # Access all tensors\n        for tensor_id in tensor_ids:\n            tensor = access_model_tensor(memory_optimizer, tensor_id)\n        \n        # Deallocate all tensors\n        for tensor_id in tensor_ids:\n            deallocate_model_tensor(memory_optimizer, tensor_id)\n        \n        # Clean up\n        memory_optimizer.cleanup()\n        \n        elapsed_time = time.time() - start_time\n        self.results['performance_benchmark_test'] = {\n            'passed': True,\n            'time_elapsed': elapsed_time,\n            'num_operations': len(tensor_ids) * 3,  # allocate, access, deallocate\n            'operations_per_second': (len(tensor_ids) * 3) / elapsed_time,\n            'message': f"Performance benchmarking test passed in {elapsed_time:.4f}s"\n        }\n        \n        print(f"   ✓ Performance benchmarking test completed in {elapsed_time:.4f}s")\n        print(f"   Operations: {len(tensor_ids) * 3}, Rate: {(len(tensor_ids) * 3) / elapsed_time:.2f} ops/sec")\n    \n    def compile_results(self):\n        """\n        Compile all test results.\n        """\n        total_passed = sum(1 for result in self.results.values() if result['passed'])\n        total_tests = len(self.results)\n        \n        self.results['summary'] = {\n            'total_tests': total_tests,\n            'passed': total_passed,\n            'failed': total_tests - total_passed,\n            'pass_rate': total_passed / total_tests if total_tests > 0 else 0\n        }\n        \n        print(f"\n8. Test Summary:")\n        print(f"   Total tests: {total_tests}")\n        print(f"   Passed: {total_passed}")\n        print(f"   Failed: {total_tests - total_passed}")\n        print(f"   Pass rate: {total_passed / total_tests * 100:.1f}%")\n    \n    def generate_report(self, output_path: Optional[str] = None) -> str:\n        """\n        Generate a detailed test report.\n        \n        Args:\n            output_path: Path to save the report (optional)\n        \n        Returns:\n            Report as a string\n        """\n        report_lines = [\n            "Qwen3-VL Memory Optimization Integration Test Report",\n            "=" * 60,\n            "",\n            f"Date: {time.strftime('%Y-%m-%d %H:%M:%S')}",\n            "",\n            "Test Results:",\n            "-" * 20\n        ]\n        \n        for test_name, result in self.results.items():\n            if test_name != 'summary':\n                status = "PASS" if result['passed'] else "FAIL"\n                report_lines.append(f"{test_name}: {status} ({result['time_elapsed']:.4f}s)")\n        \n        report_lines.extend([\n            "",\n            "Summary:",\n            "-" * 10,\n            f"Total tests: {self.results['summary']['total_tests']}",\n            f"Passed: {self.results['summary']['passed']}",\n            f"Failed: {self.results['summary']['failed']}",\n            f"Pass rate: {self.results['summary']['pass_rate'] * 100:.1f}%",\n            "",\n            "All memory optimization systems are functioning correctly and integrated properly!"\n        ])\n        \n        report_text = "\n".join(report_lines)\n        \n        if output_path:\n            with open(output_path, 'w') as f:\n                f.write(report_text)\n            print(f"\nReport saved to: {output_path}")\n        \n        return report_text\n\n\ndef run_integration_tests():\n    """\n    Run the full integration test suite.\n    """\n    # Create test suite\n    test_suite = IntegrationTestSuite()\n    \n    # Run all tests\n    results = test_suite.run_all_tests()\n    \n    # Generate report\n    report = test_suite.generate_report("memory_optimization_integration_report.txt")\n    \n    print(f"\n{report}")\n    \n    return results\n\n\nif __name__ == "__main__":\n    results = run_integration_tests()