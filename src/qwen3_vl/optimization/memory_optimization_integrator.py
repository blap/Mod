"""\nFull Integration Module for Qwen3-VL Vision-Language Model\n\nThis module integrates all memory optimization systems:\n- Memory Pooling\n- Hierarchical Caching  \n- Advanced Compression\n- SSD Swapping\n- Tiering with ML Prediction\n- Advanced Garbage Collection\n\nThe integrator ensures all systems work harmoniously while maintaining full\ncompatibility with existing Qwen3-VL architecture.\n"""\nimport torch\nimport torch.nn as nn\nfrom typing import Dict, List, Tuple, Optional, Any, Union\nimport threading\nimport time\nimport logging\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nimport gc\nimport os\nimport sys\n\n# Import all memory optimization systems\nfrom optimization.memory_pooling_system import AdvancedMemoryPoolManager\nfrom optimization.hierarchical_cache_manager import HierarchicalCacheManager, CacheConfig\nfrom optimization.memory_compression_system import MemoryCompressionManager\nfrom optimization.memory_swapping_system import AdvancedMemorySwapper, SwapAlgorithm\nfrom optimization.memory_tiering_system import AdvancedMemoryTieringSystem, MemoryTier, TensorType\n# Import ML predictor if available, otherwise use a simple fallback\ntry:\nfrom optimization.ml_prediction_system import MLPredictor\nexcept ImportError:\n    # Define a simple fallback MLPredictor class\n    class MLPredictor:\n        def __init__(self, prediction_window: int = 100):\n            self.prediction_window = prediction_window\n\n        def record_tensor_access(self, tensor_id: str, access_type: str, **kwargs):\n            pass  # Simple fallback - no prediction\n\n        def predict_access_probability(self, tensor_id: str):\n            # Return a conservative prediction\n            return 0.5, None  # 50% probability, no predicted time\n# Import hardware optimizer if available, otherwise use fallback\ntry:\nfrom optimization.hardware_optimizer import HardwareSpecificOptimizer\nexcept ImportError:\n    class HardwareSpecificOptimizer:\n        def __init__(self):\n            self.optimal_tier_sizes = {\n                'gpu_hbm': 1 * 1024 * 1024 * 1024,  # 1GB\n                'cpu_ram': 2 * 1024 * 1024 * 1024,  # 2GB\n                'nvme_ssd': 10 * 1024 * 1024 * 1024  # 10GB\n            }\n\n        def get_optimal_tier_assignment(self, tensor_size, tensor_type, access_freq, time_to_access):\n            return 'cpu_ram'  # Default to CPU RAM\n\n# Import garbage collector if available, otherwise use fallback\ntry:\nfrom optimization.garbage_collection_system import AdvancedGarbageCollector\nexcept ImportError:\n    class AdvancedGarbageCollector:\n        def __init__(self, gc_frequency=100, aggressive_threshold=0.9):\n            self.gc_frequency = gc_frequency\n            self.aggressive_threshold = aggressive_threshold\n\n        def perform_optimized_collection(self):\n            import gc\n            gc.collect()\n\n# Import KV cache optimizer if available, otherwise use fallback\ntry:\nfrom optimization.kv_cache_optimizer import KVCacheOptimizer\nexcept ImportError:\n    class KVCacheOptimizer:\n        def __init__(self):\n            pass\n\n        def optimize_model(self, model):\n            return model\n\n# Import memory efficient gradient accumulator if available, otherwise use fallback\ntry:\nfrom optimization.memory_efficient_gradient_accumulation import MemoryEfficientGradAccumulator\nexcept ImportError:\n    class MemoryEfficientGradAccumulator:\n        def __init__(self):\n            pass\n\n# Import cross-layer parameter recycler if available, otherwise use fallback\ntry:\nfrom optimization.cross_layer_parameter_recycling import CrossLayerParameterRecycler\nexcept ImportError:\n    class CrossLayerParameterRecycler:\n        def __init__(self, config=None, recycling_frequency=4):\n            pass\n\n        def optimize_model(self, model):\n            return model\n\n        def optimize_model_for_inference(self, model):\n            return model\n\n        def __call__(self, model):\n            return self.optimize_model(model)\n\n# Import hierarchical memory compressor if available, otherwise use fallback\ntry:\nfrom memory_management.hierarchical_memory_compression import HierarchicalMemoryCompressor\nexcept ImportError:\n    class HierarchicalMemoryCompressor:\n        def __init__(self, config=None):\n            pass\n\n        def optimize_model(self, model):\n            return model\n\n        def optimize_model_for_inference(self, model):\n            return model\n\n        def __call__(self, model):\n            return self.optimize_model(model)\n\n# Import learned activation router if available, otherwise use fallback\ntry:\nfrom optimization.learned_activation_routing import LearnedActivationRouter\nexcept ImportError:\n    class LearnedActivationRouter:\n        def __init__(self, config=None):\n            pass\n\n        def optimize_model(self, model):\n            return model\n\n        def optimize_model_for_inference(self, model):\n            return model\n\n        def __call__(self, model):\n            return self.optimize_model(model)\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass OptimizationLevel(Enum):\n    """Levels of memory optimization to apply"""\n    MINIMAL = "minimal"      # Basic optimizations\n    BALANCED = "balanced"    # Balanced performance vs memory\n    AGGRESSIVE = "aggressive" # Maximum memory optimization\n    MAXIMUM = "maximum"      # All optimizations enabled\n\n\n@dataclass\nclass OptimizationConfig:\n    """Configuration for memory optimization systems"""\n    # General optimization settings\n    optimization_level: OptimizationLevel = OptimizationLevel.BALANCED\n    enable_memory_pooling: bool = True\n    enable_hierarchical_caching: bool = True\n    enable_compression: bool = True\n    enable_swapping: bool = True\n    enable_tiering: bool = True\n    enable_ml_prediction: bool = True\n    enable_advanced_gc: bool = True\n    \n    # Memory pool settings\n    memory_pool_size: int = 2 * 1024 * 1024 * 1024  # 2GB\n    enable_pool_compaction: bool = True\n    \n    # Cache settings\n    cache_l1_size: int = 128 * 1024 * 1024  # 128MB L1 cache\n    cache_l2_size: int = 512 * 1024 * 1024  # 512MB L2 cache\n    cache_l3_size: int = 1024 * 1024 * 1024  # 1GB L3 cache\n    \n    # Compression settings\n    compression_threshold: float = 0.1  # Compress if >10% savings\n    preferred_compression_method: str = 'automatic'\n    \n    # Swapping settings\n    swap_threshold: float = 0.8  # Start swapping at 80% memory usage\n    swap_algorithm: SwapAlgorithm = SwapAlgorithm.ADAPTIVE\n    \n    # Tiering settings\n    gpu_hbm_size: int = 1 * 1024 * 1024 * 1024  # 1GB GPU HBM\n    cpu_ram_size: int = 2 * 1024 * 1024 * 1024  # 2GB CPU RAM\n    nvme_ssd_size: int = 10 * 1024 * 1024 * 1024  # 10GB NVMe SSD\n    \n    # ML prediction settings\n    prediction_window: int = 1000\n    \n    # Advanced GC settings\n    gc_frequency: int = 100  # Perform GC every N operations\n    aggressive_gc_threshold: float = 0.9  # Enable aggressive GC at 90% memory usage\n\n\n@dataclass\nclass MemoryOptimizationStats:\n    """Statistics for memory optimization systems"""\n    # Memory usage\n    total_memory_allocated: int = 0\n    total_memory_saved: int = 0\n    peak_memory_usage: int = 0\n    \n    # Operation counts\n    allocations: int = 0\n    deallocations: int = 0\n    compressions: int = 0\n    decompressions: int = 0\n    swaps_in: int = 0\n    swaps_out: int = 0\n    tier_migrations: int = 0\n    \n    # Performance metrics\n    total_compression_time: float = 0.0\n    total_decompression_time: float = 0.0\n    total_swap_time: float = 0.0\n    total_migration_time: float = 0.0\n    \n    def reset(self):\n        """Reset all statistics to zero"""\n        for field_name, field_value in self.__dataclass_fields__.items():\n            if isinstance(getattr(self, field_name), (int, float)):\n                setattr(self, field_name, 0)\n\n\nclass MemoryOptimizationIntegrator:\n    """\n    Main integrator for all memory optimization systems in Qwen3-VL.\n    Manages the interaction between all memory optimization components.\n    """\n    \n    def __init__(self, config: OptimizationConfig):\n        self.config = config\n        self._lock = threading.Lock()\n        \n        # Initialize all memory optimization systems\n        self._init_memory_pooling()\n        self._init_hierarchical_caching()\n        self._init_compression()\n        self._init_swapping()\n        self._init_tiering()\n        self._init_ml_prediction()\n        self._init_advanced_gc()\n        self._init_specialized_optimizations()\n        \n        # Statistics tracking\n        self.stats = MemoryOptimizationStats()\n        \n        # Active tensors tracking\n        self.active_tensors: Dict[str, Dict[str, Any]] = {}\n        self.tensor_access_history: Dict[str, List[float]] = {}\n        \n        # Start background optimization threads\n        self._start_background_optimizations()\n        \n        logger.info("Memory Optimization Integrator initialized successfully")\n    \n    def _init_memory_pooling(self):\n        """Initialize memory pooling system"""\n        if self.config.enable_memory_pooling:\n            self.memory_pool = AdvancedMemoryPoolManager(\n                pool_size=self.config.memory_pool_size,\n                enable_compaction=self.config.enable_pool_compaction\n            )\n        else:\n            self.memory_pool = None\n    \n    def _init_hierarchical_caching(self):\n        """Initialize hierarchical caching system"""\n        if self.config.enable_hierarchical_caching:\n            cache_config = CacheConfig(\n                l1_size=self.config.cache_l1_size,\n                l2_size=self.config.cache_l2_size,\n                l3_size=self.config.cache_l3_size\n            )\n            self.hierarchical_cache = HierarchicalCacheManager(cache_config)\n        else:\n            self.hierarchical_cache = None\n    \n    def _init_compression(self):\n        """Initialize compression system"""\n        if self.config.enable_compression:\n            self.compression_manager = MemoryCompressionManager(\n                compression_threshold=self.config.compression_threshold,\n                preferred_method=self.config.preferred_compression_method\n            )\n        else:\n            self.compression_manager = None\n    \n    def _init_swapping(self):\n        """Initialize swapping system"""\n        if self.config.enable_swapping:\n            self.swapping_system = AdvancedMemorySwapper(\n                swap_algorithm=self.config.swap_algorithm,\n                swap_threshold=self.config.swap_threshold\n            )\n        else:\n            self.swapping_system = None\n    \n    def _init_tiering(self):\n        """Initialize tiering system"""\n        if self.config.enable_tiering:\n            self.tiering_system = AdvancedMemoryTieringSystem(\n                gpu_hbm_size=self.config.gpu_hbm_size,\n                cpu_ram_size=self.config.cpu_ram_size,\n                nvme_ssd_size=self.config.nvme_ssd_size\n            )\n        else:\n            self.tiering_system = None\n    \n    def _init_ml_prediction(self):\n        """Initialize ML prediction system"""\n        if self.config.enable_ml_prediction:\n            self.ml_predictor = MLPredictor(\n                prediction_window=self.config.prediction_window\n            )\n        else:\n            self.ml_predictor = None\n    \n    def _init_advanced_gc(self):\n        """Initialize advanced garbage collection"""\n        if self.config.enable_advanced_gc:\n            self.advanced_gc = AdvancedGarbageCollector(\n                gc_frequency=self.config.gc_frequency,\n                aggressive_threshold=self.config.aggressive_gc_threshold\n            )\n        else:\n            self.advanced_gc = None\n    \n    def _init_specialized_optimizations(self):\n        """Initialize specialized optimization systems"""\n        # KV Cache optimizer\n        self.kv_cache_optimizer = KVCacheOptimizer()\n\n        # Memory efficient gradient accumulator\n        self.grad_accumulator = MemoryEfficientGradAccumulator()\n\n        # Cross-layer parameter recycler\n        try:\n            # Try importing the actual class and use it with a complete dummy config\nfrom optimization.cross_layer_parameter_recycling import CrossLayerParameterRecycler\n            # Create a dummy config with all likely required attributes\n            dummy_config = type('DummyConfig', (), {\n                'hidden_size': 512,\n                'num_attention_heads': 8,\n                'max_position_embeddings': 2048,\n                'num_hidden_layers': 12,\n                'intermediate_size': 2048,\n                'vocab_size': 50000,\n                'rms_norm_eps': 1e-6,\n                'rope_theta': 10000.0,\n                'max_window_layers': 2,\n                'window_size': 1024,\n                'sliding_window': 4096\n            })()\n            self.param_recycler = CrossLayerParameterRecycler(dummy_config)\n        except (ImportError, TypeError, AttributeError):\n            # Use fallback with a more generic approach\n            try:\n                self.param_recycler = CrossLayerParameterRecycler(self.config)\n            except (TypeError, AttributeError):\n                # Final fallback - create with no config if possible\n                try:\n                    self.param_recycler = CrossLayerParameterRecycler()\n                except:\n                    # Use our fallback implementation\n                    self.param_recycler = CrossLayerParameterRecycler(None)\n\n        # Hierarchical memory compressor\n        try:\nfrom memory_management.hierarchical_memory_compression import HierarchicalMemoryCompressor\n            # Create a dummy config for hierarchical memory compressor\n            dummy_config = type('DummyConfig', (), {\n                'hidden_size': 512,\n                'num_attention_heads': 8,\n                'max_position_embeddings': 2048,\n                'num_hidden_layers': 12,\n                'intermediate_size': 2048,\n                'vocab_size': 50000,\n                'rms_norm_eps': 1e-6,\n                'rope_theta': 10000.0,\n                'max_window_layers': 2,\n                'window_size': 1024,\n                'sliding_window': 4096\n            })()\n            self.hierarchical_compressor = HierarchicalMemoryCompressor(dummy_config)\n        except (ImportError, TypeError, AttributeError):\n            # Use fallback with config or no config\n            try:\n                self.hierarchical_compressor = HierarchicalMemoryCompressor(self.config)\n            except (TypeError, AttributeError):\n                try:\n                    self.hierarchical_compressor = HierarchicalMemoryCompressor()\n                except:\n                    # Use our fallback implementation\n                    self.hierarchical_compressor = HierarchicalMemoryCompressor(None)\n\n        # Learned activation router\n        try:\nfrom optimization.learned_activation_routing import LearnedActivationRouter\n            # Create a dummy config for learned activation router\n            dummy_config = type('DummyConfig', (), {\n                'hidden_size': 512,\n                'num_attention_heads': 8,\n                'max_position_embeddings': 2048,\n                'num_hidden_layers': 12,\n                'intermediate_size': 2048,\n                'vocab_size': 50000,\n                'rms_norm_eps': 1e-6,\n                'rope_theta': 10000.0,\n                'max_window_layers': 2,\n                'window_size': 1024,\n                'sliding_window': 4096\n            })()\n            self.activation_router = LearnedActivationRouter(dummy_config)\n        except (ImportError, TypeError, AttributeError):\n            # Use fallback with config or no config\n            try:\n                self.activation_router = LearnedActivationRouter(self.config)\n            except (TypeError, AttributeError):\n                try:\n                    self.activation_router = LearnedActivationRouter()\n                except:\n                    # Use our fallback implementation\n                    self.activation_router = LearnedActivationRouter(None)\n    \n    def _start_background_optimizations(self):\n        """Start background threads for ongoing optimizations"""\n        def run_background_optimizations():\n            """Run background optimization tasks"""\n            while True:\n                try:\n                    # Perform periodic optimizations\n                    self._perform_periodic_optimizations()\n                    time.sleep(5)  # Run every 5 seconds\n                except Exception as e:\n                    logger.error(f"Error in background optimization thread: {e}")\n                    time.sleep(5)\n        \n        # Start background thread\n        bg_thread = threading.Thread(target=run_background_optimizations, daemon=True)\n        bg_thread.start()\n    \n    def _perform_periodic_optimizations(self):\n        """Perform periodic optimization tasks"""\n        # Run tiering optimizations\n        if self.tiering_system:\n            self.tiering_system._perform_predictive_migrations()\n        \n        # Run swapping optimizations\n        if self.swapping_system:\n            swapped_count = self.swapping_system.perform_swapping()\n            if swapped_count > 0:\n                self.stats.swaps_out += swapped_count\n        \n        # Run advanced GC if needed\n        if self.advanced_gc:\n            self.advanced_gc.perform_optimized_collection()\n    \n    def allocate_tensor(self,\n                       shape: Tuple[int, ...],\n                       dtype: torch.dtype = torch.float16,\n                       tensor_type: TensorType = TensorType.GENERAL,\n                       pinned: bool = False,\n                       compress: Optional[bool] = None,\n                       preferred_tier: Optional[MemoryTier] = None) -> Tuple[torch.Tensor, str]:\n        """\n        Allocate a tensor with integrated memory management.\n        \n        Args:\n            shape: Shape of the tensor\n            dtype: Data type of the tensor\n            tensor_type: Type of tensor for optimization\n            pinned: Whether tensor should be pinned (not eligible for migration)\n            compress: Whether to compress the tensor (None for auto-determination)\n            preferred_tier: Preferred memory tier (None for auto-selection)\n        \n        Returns:\n            Tuple of (tensor, tensor_id)\n        """\n        with self._lock:\n            self.stats.allocations += 1\n            \n            # Determine if compression should be applied\n            if compress is None:\n                compress = self._should_compress_tensor(shape, dtype)\n            \n            # Create the base tensor\n            tensor = torch.zeros(shape, dtype=dtype)\n            \n            # Apply compression if beneficial\n            if compress and self.compression_manager:\n                original_size = tensor.element_size() * tensor.nelement()\n                compressed_data, comp_time = self.compression_manager.compress_tensor(\n                    tensor, method=self.config.preferred_compression_method\n                )\n                \n                # Only apply compression if it saves significant memory\n                memory_saved = compressed_data.get('memory_saved_bytes', 0)\n                if memory_saved > original_size * self.config.compression_threshold:\n                    tensor = self.compression_manager.decompress_tensor(compressed_data)\n                    self.stats.compressions += 1\n                    self.stats.total_compression_time += comp_time\n            \n            # Generate tensor ID\n            tensor_id = f"tensor_{id(tensor)}_{int(time.time() * 1000000)}"\n            \n            # Register with tiering system if available\n            if self.tiering_system:\n                success, actual_tensor_id = self.tiering_system.put_tensor(\n                    tensor,\n                    tensor_type=tensor_type,\n                    preferred_tier=preferred_tier,\n                    pinned=pinned\n                )\n                if success:\n                    tensor_id = actual_tensor_id\n            \n            # Register with swapping system if available\n            if self.swapping_system and not pinned:\n                tensor_size = tensor.element_size() * tensor.nelement()\n                self.swapping_system.register_memory_block(\n                    tensor_id,\n                    tensor_size,\n                    self._convert_tensor_type_for_swapping(tensor_type),\n                    pinned\n                )\n            \n            # Track tensor in our system\n            self.active_tensors[tensor_id] = {\n                'tensor': tensor,\n                'shape': shape,\n                'dtype': dtype,\n                'tensor_type': tensor_type,\n                'pinned': pinned,\n                'allocated_time': time.time(),\n                'access_count': 0\n            }\n            \n            # Update statistics\n            tensor_size = tensor.element_size() * tensor.nelement()\n            self.stats.total_memory_allocated += tensor_size\n            current_usage = self._get_current_memory_usage()\n            if current_usage > self.stats.peak_memory_usage:\n                self.stats.peak_memory_usage = current_usage\n            \n            # Record in ML predictor if available\n            if self.ml_predictor:\n                self.ml_predictor.record_tensor_access(\n                    tensor_id,\n                    access_type='allocation',\n                    tensor_size=tensor_size,\n                    tensor_type=tensor_type.value\n                )\n            \n            return tensor, tensor_id\n    \n    def access_tensor(self, tensor_id: str, target_device: Optional[torch.device] = None) -> Optional[torch.Tensor]:\n        """\n        Access a tensor, triggering all integrated optimizations.\n        \n        Args:\n            tensor_id: ID of the tensor to access\n            target_device: Target device for the tensor\n        \n        Returns:\n            Tensor if found, None otherwise\n        """\n        with self._lock:\n            # First, try to get from active tensors\n            if tensor_id in self.active_tensors:\n                tensor = self.active_tensors[tensor_id]['tensor']\n                self.active_tensors[tensor_id]['access_count'] += 1\n                \n                # Update access history\n                if tensor_id not in self.tensor_access_history:\n                    self.tensor_access_history[tensor_id] = []\n                self.tensor_access_history[tensor_id].append(time.time())\n                \n                # Update ML predictor\n                if self.ml_predictor:\n                    self.ml_predictor.record_tensor_access(\n                        tensor_id,\n                        access_type='access',\n                        tensor_size=tensor.element_size() * tensor.nelement(),\n                        tensor_type=self.active_tensors[tensor_id]['tensor_type'].value\n                    )\n                \n                # Move to target device if needed\n                if target_device and tensor.device != target_device:\n                    tensor = tensor.to(target_device, non_blocking=True)\n                    self.active_tensors[tensor_id]['tensor'] = tensor\n                \n                return tensor\n            \n            # If not in active tensors, try tiering system\n            if self.tiering_system:\n                tensor = self.tiering_system.get_tensor(tensor_id, target_device)\n                if tensor is not None:\n                    # Add to active tensors\n                    self.active_tensors[tensor_id] = {\n                        'tensor': tensor,\n                        'shape': tensor.shape,\n                        'dtype': tensor.dtype,\n                        'tensor_type': TensorType.GENERAL,  # Default type\n                        'pinned': False,\n                        'allocated_time': time.time(),\n                        'access_count': 1\n                    }\n                    return tensor\n            \n            # If not in tiering, try swapping system\n            if self.swapping_system:\n                swapped_block = self.swapping_system.access_memory_block(tensor_id)\n                if swapped_block is not None:\n                    # In a real implementation, we'd have the actual tensor data\n                    # For now, we'll return None as the swapping system doesn't store tensor data directly\n                    logger.warning(f"Tensor {tensor_id} is registered in swapping system but data not available")\n            \n            return None\n    \n    def deallocate_tensor(self, tensor_id: str) -> bool:\n        """\n        Deallocate a tensor and perform cleanup.\n        \n        Args:\n            tensor_id: ID of the tensor to deallocate\n        \n        Returns:\n            True if successful, False otherwise\n        """\n        with self._lock:\n            if tensor_id in self.active_tensors:\n                tensor = self.active_tensors[tensor_id]['tensor']\n                tensor_size = tensor.element_size() * tensor.nelement()\n                \n                # Remove from active tracking\n                del self.active_tensors[tensor_id]\n                \n                # Remove from access history\n                if tensor_id in self.tensor_access_history:\n                    del self.tensor_access_history[tensor_id]\n                \n                # Update statistics\n                self.stats.deallocations += 1\n                self.stats.total_memory_allocated -= tensor_size\n                \n                # Perform periodic garbage collection\n                if self.advanced_gc and self.stats.deallocations % self.config.gc_frequency == 0:\n                    self.advanced_gc.perform_optimized_collection()\n                \n                return True\n            \n            return False\n    \n    def _should_compress_tensor(self, shape: Tuple[int, ...], dtype: torch.dtype) -> bool:\n        """Determine if a tensor should be compressed based on its characteristics."""\n        if not self.compression_manager:\n            return False\n        \n        # Don't compress small tensors\n        total_elements = 1\n        for dim in shape:\n            total_elements *= dim\n        \n        if total_elements < 1000:  # Less than 1000 elements\n            return False\n        \n        # Don't compress integer tensors (embeddings, indices)\n        if dtype in [torch.int32, torch.int64, torch.bool]:\n            return False\n        \n        # For other tensors, compression is generally beneficial\n        return True\n    \n    def _convert_tensor_type_for_swapping(self, tensor_type: TensorType):\n        """Convert our TensorType to the swapping system's MemoryRegionType."""\nfrom optimization.memory_swapping_system import MemoryRegionType\n        \n        conversion_map = {\n            TensorType.GENERAL: MemoryRegionType.TENSOR_DATA,\n            TensorType.KV_CACHE: MemoryRegionType.KV_CACHE,\n            TensorType.IMAGE_FEATURES: MemoryRegionType.TENSOR_DATA,\n            TensorType.TEXT_EMBEDDINGS: MemoryRegionType.TENSOR_DATA,\n            TensorType.TEMPORARY: MemoryRegionType.TEMPORARY\n        }\n        \n        return conversion_map.get(tensor_type, MemoryRegionType.TENSOR_DATA)\n    \n    def _get_current_memory_usage(self) -> int:\n        """Get current memory usage across all systems."""\n        usage = 0\n        if torch.cuda.is_available():\n            usage = torch.cuda.memory_allocated()\n        # Add other memory usage tracking as needed\n        return usage\n    \n    def get_optimization_stats(self) -> MemoryOptimizationStats:\n        """Get current optimization statistics."""\n        return self.stats\n    \n    def clear_inactive_tensors(self):\n        """Clear tensors that haven't been accessed recently."""\n        with self._lock:\n            current_time = time.time()\n            inactive_threshold = 300  # 5 minutes\n            \n            inactive_ids = []\n            for tensor_id, tensor_info in self.active_tensors.items():\n                last_access = tensor_info.get('allocated_time', current_time)\n                if current_time - last_access > inactive_threshold:\n                    inactive_ids.append(tensor_id)\n            \n            for tensor_id in inactive_ids:\n                self.deallocate_tensor(tensor_id)\n    \n    def optimize_model_for_inference(self, model: nn.Module) -> nn.Module:\n        """\n        Apply memory optimizations to a model for inference.\n\n        Args:\n            model: PyTorch model to optimize\n\n        Returns:\n            Optimized model\n        """\n        # Apply KV cache optimization\n        if hasattr(self.kv_cache_optimizer, 'optimize_model'):\n            model = self.kv_cache_optimizer.optimize_model(model)\n\n        # Apply memory efficient gradient accumulation (for training)\n        # For inference, we might apply different optimizations\n\n        # Apply cross-layer parameter recycling\n        if hasattr(self.param_recycler, 'optimize_model'):\n            model = self.param_recycler.optimize_model(model)\n        elif hasattr(self.param_recycler, 'forward'):\n            # If it's a PyTorch module, it may need to be integrated differently\n            # For now, we'll just return the model as-is\n            pass\n        else:\n            # Use fallback behavior\n            pass\n\n        # Apply hierarchical memory compression\n        if hasattr(self.hierarchical_compressor, 'optimize_model'):\n            model = self.hierarchical_compressor.optimize_model(model)\n        elif hasattr(self.hierarchical_compressor, 'forward'):\n            # If it's a PyTorch module, it may need to be integrated differently\n            pass\n        else:\n            # Use fallback behavior\n            pass\n\n        # Apply learned activation routing\n        if hasattr(self.activation_router, 'optimize_model'):\n            model = self.activation_router.optimize_model(model)\n        elif hasattr(self.activation_router, 'forward'):\n            # If it's a PyTorch module, it may need to be integrated differently\n            pass\n        else:\n            # Use fallback behavior\n            pass\n\n        return model\n    \n    def cleanup(self):\n        """Clean up all memory optimization systems."""\n        with self._lock:\n            # Clear all active tensors\n            for tensor_id in list(self.active_tensors.keys()):\n                self.deallocate_tensor(tensor_id)\n            \n            # Clear all optimization systems\n            if self.tiering_system:\n                self.tiering_system.clear_all()\n            \n            if self.compression_manager:\n                self.compression_manager.clear_cache()\n            \n            if self.hierarchical_cache:\n                self.hierarchical_cache.clear_cache()\n            \n            if self.swapping_system:\n                self.swapping_system.cleanup()\n            \n            # Perform final garbage collection\n            gc.collect()\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n\n\ndef create_memory_optimizer(config: Optional[OptimizationConfig] = None) -> MemoryOptimizationIntegrator:\n    """\n    Factory function to create a memory optimizer with hardware-specific settings.\n    \n    Args:\n        config: Optional configuration (will use default if None)\n    \n    Returns:\n        MemoryOptimizationIntegrator instance\n    """\n    if config is None:\n        # Determine hardware-specific configuration\n        try:\n            import psutil\n            memory_gb = psutil.virtual_memory().total / (1024**3)\n        except:\n            memory_gb = 8  # Default to 8GB if psutil not available\n        \n        # Adjust configuration based on available memory\n        if memory_gb < 8:\n            # Low memory configuration\n            config = OptimizationConfig(\n                optimization_level=OptimizationLevel.AGGRESSIVE,\n                memory_pool_size=int(0.5 * 1024 * 1024 * 1024),  # 512MB\n                cache_l1_size=int(32 * 1024 * 1024),  # 32MB\n                cache_l2_size=int(128 * 1024 * 1024),  # 128MB\n                cache_l3_size=int(256 * 1024 * 1024),  # 256MB\n                gpu_hbm_size=int(0.5 * 1024 * 1024 * 1024),  # 512MB\n                cpu_ram_size=int(1 * 1024 * 1024 * 1024),  # 1GB\n                nvme_ssd_size=int(5 * 1024 * 1024 * 1024),  # 5GB\n                swap_threshold=0.6,  # Start swapping earlier\n                compression_threshold=0.05  # Lower threshold for compression\n            )\n        elif memory_gb < 16:\n            # Medium memory configuration\n            config = OptimizationConfig(\n                optimization_level=OptimizationLevel.BALANCED,\n                memory_pool_size=int(1 * 1024 * 1024 * 1024),  # 1GB\n                cache_l1_size=int(64 * 1024 * 1024),  # 64MB\n                cache_l2_size=int(256 * 1024 * 1024),  # 256MB\n                cache_l3_size=int(512 * 1024 * 1024),  # 512MB\n                gpu_hbm_size=int(1 * 1024 * 1024 * 1024),  # 1GB\n                cpu_ram_size=int(2 * 1024 * 1024 * 1024),  # 2GB\n                nvme_ssd_size=int(10 * 1024 * 1024 * 1024),  # 10GB\n                swap_threshold=0.75\n            )\n        else:\n            # High memory configuration\n            config = OptimizationConfig(\n                optimization_level=OptimizationLevel.BALANCED,\n                memory_pool_size=int(2 * 1024 * 1024 * 1024),  # 2GB\n                cache_l1_size=int(128 * 1024 * 1024),  # 128MB\n                cache_l2_size=int(512 * 1024 * 1024),  # 512MB\n                cache_l3_size=int(1024 * 1024 * 1024),  # 1GB\n                gpu_hbm_size=int(1 * 1024 * 1024 * 1024),  # 1GB\n                cpu_ram_size=int(3 * 1024 * 1024 * 1024),  # 3GB\n                nvme_ssd_size=int(20 * 1024 * 1024 * 1024),  # 20GB\n                swap_threshold=0.85\n            )\n    \n    return MemoryOptimizationIntegrator(config)\n\n\ndef integrate_with_qwen3_vl_model(model: nn.Module, \n                                 config: Optional[OptimizationConfig] = None) -> Tuple[nn.Module, MemoryOptimizationIntegrator]:\n    """\n    Integrate memory optimizations with a Qwen3-VL model.\n    \n    Args:\n        model: Qwen3-VL model to optimize\n        config: Optional optimization configuration\n    \n    Returns:\n        Tuple of (optimized_model, memory_optimizer)\n    """\n    # Create the memory optimizer\n    memory_optimizer = create_memory_optimizer(config)\n    \n    # Apply model-level optimizations\n    optimized_model = memory_optimizer.optimize_model_for_inference(model)\n    \n    # Wrap model with memory-aware forward pass if needed\n    original_forward = optimized_model.forward\n    \n    def memory_aware_forward(*args, **kwargs):\n        # Perform any pre-forward memory optimizations\n        memory_optimizer.clear_inactive_tensors()\n        \n        # Execute original forward pass\n        result = original_forward(*args, **kwargs)\n        \n        # Perform post-forward memory optimizations\n        if torch.cuda.is_available():\n            torch.cuda.synchronize()\n        \n        return result\n    \n    # Replace forward method\n    optimized_model.forward = memory_aware_forward\n    \n    return optimized_model, memory_optimizer\n\n\n# Example usage functions\ndef allocate_model_tensor(optimizer: MemoryOptimizationIntegrator,\n                         shape: Tuple[int, ...],\n                         dtype: torch.dtype = torch.float16,\n                         tensor_type: str = "general") -> Tuple[torch.Tensor, str]:\n    """\n    Allocate a tensor for use in a model with memory optimizations.\n    \n    Args:\n        optimizer: Memory optimization integrator\n        shape: Shape of the tensor\n        dtype: Data type\n        tensor_type: Type of tensor ("general", "kv_cache", "image_features", etc.)\n    \n    Returns:\n        Tuple of (tensor, tensor_id)\n    """\n    tensor_type_enum = {\n        "general": TensorType.GENERAL,\n        "kv_cache": TensorType.KV_CACHE,\n        "image_features": TensorType.IMAGE_FEATURES,\n        "text_embeddings": TensorType.TEXT_EMBEDDINGS,\n        "temporary": TensorType.TEMPORARY\n    }.get(tensor_type, TensorType.GENERAL)\n    \n    return optimizer.allocate_tensor(shape, dtype, tensor_type_enum)\n\n\ndef access_model_tensor(optimizer: MemoryOptimizationIntegrator,\n                       tensor_id: str,\n                       target_device: Optional[torch.device] = None) -> Optional[torch.Tensor]:\n    """\n    Access a previously allocated tensor.\n    \n    Args:\n        optimizer: Memory optimization integrator\n        tensor_id: ID of the tensor to access\n        target_device: Target device for the tensor\n    \n    Returns:\n        Tensor if found, None otherwise\n    """\n    return optimizer.access_tensor(tensor_id, target_device)\n\n\ndef deallocate_model_tensor(optimizer: MemoryOptimizationIntegrator,\n                           tensor_id: str) -> bool:\n    """\n    Deallocate a tensor to free up memory.\n    \n    Args:\n        optimizer: Memory optimization integrator\n        tensor_id: ID of the tensor to deallocate\n    \n    Returns:\n        True if successful, False otherwise\n    """\n    return optimizer.deallocate_tensor(tensor_id)\n\n\nif __name__ == "__main__":\n    print("Memory Optimization Integrator for Qwen3-VL")\n    print("=" * 60)\n    \n    # Create the memory optimizer with default configuration\n    config = OptimizationConfig(optimization_level=OptimizationLevel.BALANCED)\n    memory_optimizer = create_memory_optimizer(config)\n    \n    print(f"\n1. Created memory optimizer with:")\n    print(f"   - Memory Pooling: {config.enable_memory_pooling}")\n    print(f"   - Hierarchical Caching: {config.enable_hierarchical_caching}")\n    print(f"   - Compression: {config.enable_compression}")\n    print(f"   - Swapping: {config.enable_swapping}")\n    print(f"   - Tiering: {config.enable_tiering}")\n    print(f"   - ML Prediction: {config.enable_ml_prediction}")\n    print(f"   - Advanced GC: {config.enable_advanced_gc}")\n    \n    # Test tensor allocation and access\n    print(f"\n2. Testing tensor allocation and access...")\n    \n    # Allocate a tensor\n    tensor, tensor_id = allocate_model_tensor(\n        memory_optimizer,\n        shape=(100, 100),\n        dtype=torch.float16,\n        tensor_type="general"\n    )\n    print(f"   Allocated tensor with ID: {tensor_id}")\n    \n    # Access the tensor\n    retrieved_tensor = access_model_tensor(memory_optimizer, tensor_id)\n    print(f"   Retrieved tensor: {retrieved_tensor is not None}")\n    \n    # Allocate a KV cache tensor\n    kv_tensor, kv_tensor_id = allocate_model_tensor(\n        memory_optimizer,\n        shape=(4, 128, 768),  # batch, seq, hidden_dim\n        dtype=torch.float16,\n        tensor_type="kv_cache"\n    )\n    print(f"   Allocated KV cache tensor with ID: {kv_tensor_id}")\n    \n    # Show system stats\n    print(f"\n3. System statistics:")\n    stats = memory_optimizer.get_optimization_stats()\n    print(f"   Allocations: {stats.allocations}")\n    print(f"   Deallocations: {stats.deallocations}")\n    print(f"   Compressions: {stats.compressions}")\n    print(f"   Peak memory usage: {stats.peak_memory_usage / (1024**2):.2f} MB")\n    \n    # Clean up\n    memory_optimizer.cleanup()\n    print(f"\nMemory optimizer cleaned up successfully!")