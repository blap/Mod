{
  "plugin_name": "Qwen3-VL-2B-Instruct",
  "plugin_type": "model_component",
  "model_path": "H:/Qwen3-VL-2B-Instruct",
  "parameters": {
    "num_hidden_layers": 24,
    "num_attention_heads": 32,
    "hidden_size": 2048,
    "intermediate_size": 5504,
    "num_key_value_heads": 32,
    "max_position_embeddings": 32768,
    "rope_theta": 1000000.0,
    "vocab_size": 151936,
    "vision_config": {
      "image_size": 448,
      "patch_size": 14,
      "num_channels": 3,
      "hidden_size": 1024,
      "num_hidden_layers": 24,
      "num_attention_heads": 16
    },
    "gradient_checkpointing": true,
    "use_cache": true,
    "torch_dtype": "float16",
    "device_map": "auto",
    "enable_kernel_fusion": true,
    "kernel_fusion_patterns": ["linear_relu", "linear_gelu", "matmul_add", "add_layer_norm"],
    "use_custom_cuda_kernels": true,
    "custom_kernel_fallback_enabled": true,
    "enable_distributed_simulation": true,
    "num_distributed_partitions": 2,
    "partition_strategy": "layer_wise",
    "memory_per_partition_gb": 3.0,
    "overlap_communication": true,
    "pipeline_depth": 1,
    "sync_method": "barrier",
    "enable_gradient_checkpointing_in_distributed": true,
    "enable_tensor_parallelism": false,
    "tensor_parallel_size": 1,
    "enable_tensor_compression": true,
    "tensor_compression_method": "incremental_pca",
    "tensor_compression_ratio": 0.5,
    "tensor_compression_max_components": 256,
    "compression_memory_threshold_high": 0.8,
    "compression_memory_threshold_critical": 0.9,
    "enable_adaptive_compression": true,
    "enable_activation_compression": true,
    "compression_update_frequency": 100,
    "enable_sharding": true,
    "num_shards": 500,
    "sharding_storage_path": "./shards/qwen3_vl_2b",
    "max_loaded_shards": 10,
    "sharding_priority": "high",
    "enable_model_surgery": true,
    "surgery_enabled": true,
    "auto_identify_components": true,
    "surgery_priority_threshold": 10,
    "analysis_only": false,
    "preserve_components": ["lm_head", "embed_tokens", "visual_encoder"],
    "components_to_remove": null,
    "enable_pipeline": true,
    "pipeline_checkpoint_dir": "./pipeline_checkpoints/qwen3_vl_2b",
    "pipeline_max_concurrent_stages": 1,
    "pipeline_cleanup_after_completion": true,
    "pipeline_stages": [
      {
        "name": "tokenization",
        "function": "tokenize",
        "input_keys": ["text"],
        "output_keys": ["tokens"],
        "cache_intermediates": true
      },
      {
        "name": "model_inference",
        "function": "infer",
        "input_keys": ["tokens"],
        "output_keys": ["model_outputs"],
        "cache_intermediates": true
      },
      {
        "name": "decoding",
        "function": "detokenize",
        "input_keys": ["model_outputs"],
        "output_keys": ["decoded_text"],
        "cache_intermediates": false
      }
    ],
    "enable_activation_offloading": true,
    "activation_max_memory_ratio": 0.7,
    "activation_offload_directory": "./activation_offloads/qwen3_vl_2b",
    "activation_page_size_mb": 8,
    "activation_eviction_policy": "predictive",
    "activation_offloading_priority": "medium",
    "enable_predictive_activation_offloading": true,
    "proactive_activation_offloading_interval": 5.0
  },
  "input_formats": ["text", "image", "multimodal_dict"],
  "output_formats": ["text", "tensor"],
  "dependencies": ["torch", "transformers", "pillow", "accelerate"],
  "enabled": true,
  "priority": 85,
  "created_at": "2026-01-05T00:00:00",
  "updated_at": "2026-01-05T00:00:00",
  "metadata": {
    "version": "1.0.0",
    "author": "Qwen Team",
    "description": "Configuration for Qwen3-VL-2B-Instruct multimodal vision-language model",
    "model_family": "Qwen3-VL",
    "model_size": "2B",
    "required_memory_gb": 6.0,
    "supported_modalities": ["text", "image"],
    "tags": ["multimodal", "vision-language", "kernel-fusion", "cuda-kernels", "distributed-simulation", "extreme-sharding", "streaming-loader", "disk-pipeline"]
  }
}