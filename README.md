# Inference-PIO

Inference-PIO is a modular, high-performance inference system built on a self-contained plugin architecture. Each model is completely independent with its own configuration, tests, and benchmarks. The system supports advanced models like GLM-4.7, Qwen3-VL, and Qwen3-Coder.

## ğŸ“š Documentation

*   **[Getting Started](docs/guides/getting_started.md):** Installation, basic usage, and configuration.
*   **[Creating a Model Plugin](docs/creating_model_plugin_guide.md):** Guide to creating new model plugins.
*   **[Supported Models](docs/api/models.md):** List of models and their capabilities.
*   **[System Architecture](docs/api/architecture.md):** Deep dive into the plugin system and design.
*   **[Advanced Features](docs/api/advanced_features.md):** Multimodal attention, streaming, and NAS.
*   **[Benchmarking](docs/guides/benchmarking.md):** Performance measurement guide.
*   **[Coding Standards](docs/standards/CODING.md):** Code style and naming conventions.
*   **[Docstring Standards](docs/standards/DOCSTRINGS.md):** Documentation format guidelines.
*   **[Comment Standards](docs/standards/COMMENTS.md):** Inline and block comment guidelines.
*   **[Testing Standards](docs/standards/TESTING.md):** Test organization and naming conventions.
*   **[Benchmarking Standards](docs/standards/BENCHMARKS.md):** Performance measurement guidelines.

## ğŸ›  Project Structure

```
.
â”œâ”€â”€ benchmark_results/              # General benchmark results
â”‚   â””â”€â”€ general/                  # Cross-model benchmark data
â”œâ”€â”€ docs/                         # Documentation (Guides, API, Standards)
â”œâ”€â”€ examples/                     # Example usage scripts
â”œâ”€â”€ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ benchmarking/            # Scripts for running benchmarks
â”‚   â”œâ”€â”€ development/             # Development and debugging scripts
â”‚   â”œâ”€â”€ testing/                 # Scripts for running tests
â”‚   â””â”€â”€ utils/                   # General utility scripts
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ common/                  # Shared utilities and interfaces
â”‚   â”œâ”€â”€ configs/                 # Global configuration
â”‚   â”œâ”€â”€ inference/               # Inference engine components
â”‚   â”œâ”€â”€ models/                  # Individual self-contained model plugins
â”‚   â”‚   â”œâ”€â”€ glm_4_7_flash/       # GLM-4.7 Flash model with all components
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py      # Module entry point
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py        # Model-specific config
â”‚   â”‚   â”‚   â”œâ”€â”€ model.py         # Core model implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ plugin.py        # Plugin interface implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ plugin_manifest.json # Plugin metadata for discovery
â”‚   â”‚   â”‚   â”œâ”€â”€ architecture/    # Architecture-specific implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ attention/       # Attention mechanisms
â”‚   â”‚   â”‚   â”œâ”€â”€ fused_layers/    # Fused layer implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ kv_cache/        # KV cache management
â”‚   â”‚   â”‚   â”œâ”€â”€ mlp/             # MLP implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ rotary_embeddings/ # Rotary embedding implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ specific_optimizations/ # Model-specific optimizations
â”‚   â”‚   â”‚   â”œâ”€â”€ configs/         # Configuration files
â”‚   â”‚   â”‚   â”œâ”€â”€ tests/           # Legacy model-specific tests (deprecated)
â”‚   â”‚   â”‚   â”œâ”€â”€ benchmarks/      # Model-specific benchmarks
â”‚   â”‚   â”‚   â””â”€â”€ README.md        # Model-specific documentation
â”‚   â”‚   â”œâ”€â”€ qwen3_0_6b/          # Qwen3-0.6B model with all components
â”‚   â”‚   â”œâ”€â”€ qwen3_4b_instruct_2507/ # Qwen3-4B-Instruct-2507 model with all components
â”‚   â”‚   â”œâ”€â”€ qwen3_coder_30b/     # Qwen3-Coder-30B model with all components
â”‚   â”‚   â””â”€â”€ qwen3_vl_2b/         # Qwen3-VL-2B model with all components
â”‚   â”œâ”€â”€ plugins/                 # Plugin system infrastructure
â”‚   â”‚   â”œâ”€â”€ __init__.py          # Plugin system entry point
â”‚   â”‚   â”œâ”€â”€ base/                # Base plugin interfaces
â”‚   â”‚   â”œâ”€â”€ cpu/                 # CPU-specific plugins
â”‚   â”‚   â”œâ”€â”€ intel/               # Intel-specific plugins
â”‚   â”‚   â””â”€â”€ manager.py           # Plugin manager implementation
â”‚   â”œâ”€â”€ utils/                   # Utility functions
â”‚   â””â”€â”€ model_factory.py         # Model creation factory
â”œâ”€â”€ tests/                       # Organized test structure
â”‚   â”œâ”€â”€ models/                  # Model-specific tests (organized by model)
â”‚   â”‚   â”œâ”€â”€ glm_4_7_flash/       # Tests for GLM-4.7 Flash model
â”‚   â”‚   â”œâ”€â”€ qwen3_0_6b/          # Tests for Qwen3-0.6B model
â”‚   â”‚   â”œâ”€â”€ qwen3_4b_instruct_2507/ # Tests for Qwen3-4B-Instruct-2507 model
â”‚   â”‚   â”œâ”€â”€ qwen3_coder_30b/     # Tests for Qwen3-Coder-30B model
â”‚   â”‚   â””â”€â”€ qwen3_vl_2b/         # Tests for Qwen3-VL-2B model
â”‚   â”œâ”€â”€ unit/                    # General unit tests
â”‚   â”œâ”€â”€ integration/             # General integration tests
â”‚   â””â”€â”€ performance/             # General performance tests
â”œâ”€â”€ benchmarks/                  # General benchmarks
â””â”€â”€ dev_tools/                   # Development tools and utilities
```

## ğŸš€ Quick Start

```bash
pip install -r requirements.txt
python -c "from src.model_factory import create_model; m=create_model('glm_4_7_flash'); m.initialize(); print(m.infer('Hello'))"
```

## ğŸ§© Plugin Discovery System

The system automatically discovers new plugins through:
1. **Directory scanning**: Looks for model directories in `src/models/`
2. **Manifest files**: Each model has a `plugin_manifest.json` file
3. **Auto-registration**: Plugins are automatically registered without manual imports

## ğŸ—ï¸ Self-Contained Architecture

Each model plugin is completely independent with its own:
- Configuration files in `configs/`
- Model implementation in `model.py`
- Plugin interface in `plugin.py`
- Tests in `tests/` (organized by model)
- Benchmarks in `benchmarks/` (organized by model)
- Optimization implementations in dedicated subdirectories

This ensures that each model can be developed, tested, and deployed independently.

## ğŸ§ª Testing

The project now uses an organized test structure that mirrors the `src/models` hierarchy:

```
tests/
â”œâ”€â”€ models/                  # Model-specific tests
â”‚   â”œâ”€â”€ glm_4_7_flash/       # Tests for GLM-4.7 Flash model
â”‚   â”‚   â”œâ”€â”€ unit/            # Unit tests
â”‚   â”‚   â”œâ”€â”€ integration/     # Integration tests
â”‚   â”‚   â””â”€â”€ performance/     # Performance tests
â”‚   â”œâ”€â”€ qwen3_0_6b/          # Tests for Qwen3-0.6B model
â”‚   â”œâ”€â”€ qwen3_4b_instruct_2507/ # Tests for Qwen3-4B-Instruct-2507 model
â”‚   â”œâ”€â”€ qwen3_coder_30b/     # Tests for Qwen3-Coder-30B model
â”‚   â””â”€â”€ qwen3_vl_2b/         # Tests for Qwen3-VL-2B model
â”œâ”€â”€ unit/                    # General unit tests
â”œâ”€â”€ integration/             # General integration tests
â””â”€â”€ performance/             # General performance tests
```

To run tests for a specific model:
```bash
pytest tests/models/qwen3_0_6b/
```

To run unit tests for a specific model:
```bash
pytest tests/models/qwen3_0_6b/unit/
```

## ğŸ¤ Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for developer guidelines.

## ğŸ§ª Testes com Funcionalidades Reais

O projeto inclui uma suite abrangente de testes que utilizam funcionalidades reais em vez de simulaÃ§Ãµes excessivas. Esses testes exercitam os caminhos crÃ­ticos do sistema com dados e operaÃ§Ãµes reais, mantendo a eficiÃªncia enquanto aumentam a fidelidade Ã  realidade.

### Tipos de Testes Reais

- **Testes de Funcionalidade**: Verificam a funcionalidade bÃ¡sica do sistema usando componentes reais
- **Testes de IntegraÃ§Ã£o**: Testam a interaÃ§Ã£o entre mÃºltiplos componentes do sistema
- **Testes de Desempenho**: Medem mÃ©tricas reais de desempenho em vez de simulaÃ§Ãµes
- **Testes Funcionais**: Verificam o comportamento do sistema do ponto de vista do usuÃ¡rio
- **Testes de RegressÃ£o**: Garantem que alteraÃ§Ãµes nÃ£o quebrem funcionalidades existentes

### ExecuÃ§Ã£o dos Testes Reais

Para executar todos os testes com funcionalidades reais:

```bash
python run_real_tests.py
```

Ou executar testes especÃ­ficos:

```bash
# Testes de funcionalidade
python -m pytest test_real_functionality.py -v

# Testes de integraÃ§Ã£o
python -m pytest test_real_integration.py -v

# Testes de desempenho
python -m pytest test_real_performance.py -v

# Testes funcionais
python -m pytest test_real_functional.py -v

# Testes de regressÃ£o
python -m pytest test_real_regression.py -v
```

## ğŸ”Œ Arquitetura ExtensÃ­vel

O projeto implementa uma arquitetura flexÃ­vel e extensÃ­vel para fÃ¡cil inclusÃ£o de novos modelos e tipos de teste/benchmark. Cada modelo/plugin Ã© completamente independente com sua prÃ³pria configuraÃ§Ã£o, testes e benchmarks.

### Adicionando Novos Modelos

Use o assistente de criaÃ§Ã£o de modelos para gerar automaticamente toda a estrutura necessÃ¡ria:

```bash
python create_model.py --name meu-novo-modelo --description "DescriÃ§Ã£o do novo modelo"
```

### Adicionando Novos Tipos de Teste

Crie novos tipos de testes com o assistente de criaÃ§Ã£o de testes:

```bash
python create_test_type.py --name tipo-de-teste --description "DescriÃ§Ã£o do tipo de teste"
```

### Adicionando Novos Tipos de Benchmark

Adicione novos benchmarks com o assistente de criaÃ§Ã£o de benchmarks:

```bash
python create_benchmark_type.py --name tipo-de-benchmark --description "DescriÃ§Ã£o do tipo de benchmark"
```

Para mais detalhes sobre a arquitetura extensÃ­vel, consulte [EXTENSIBLE_ARCHITECTURE_README.md](EXTENSIBLE_ARCHITECTURE_README.md) e [MODEL_PLUGIN_ARCHITECTURE.md](MODEL_PLUGIN_ARCHITECTURE.md).
